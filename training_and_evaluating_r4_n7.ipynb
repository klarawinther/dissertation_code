{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation notebook\n",
    "Round 4, no. 7 binary classification based on class 1 (drained) and 4 (restored) from the original dataset and trained only on bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B9</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>sample_location_id</th>\n",
       "      <th>classes</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>SAVI</th>\n",
       "      <th>GNDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00495</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.03610</td>\n",
       "      <td>0.05020</td>\n",
       "      <td>0.09065</td>\n",
       "      <td>0.13930</td>\n",
       "      <td>0.15855</td>\n",
       "      <td>0.18270</td>\n",
       "      <td>0.19205</td>\n",
       "      <td>0.19175</td>\n",
       "      <td>0.20290</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.568914</td>\n",
       "      <td>0.246737</td>\n",
       "      <td>-0.052386</td>\n",
       "      <td>0.271183</td>\n",
       "      <td>0.670018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01040</td>\n",
       "      <td>0.02405</td>\n",
       "      <td>0.03980</td>\n",
       "      <td>0.05720</td>\n",
       "      <td>0.10385</td>\n",
       "      <td>0.16755</td>\n",
       "      <td>0.19370</td>\n",
       "      <td>0.21600</td>\n",
       "      <td>0.23420</td>\n",
       "      <td>0.24700</td>\n",
       "      <td>0.22290</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.581259</td>\n",
       "      <td>0.287926</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>0.308070</td>\n",
       "      <td>0.688819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01510</td>\n",
       "      <td>0.02905</td>\n",
       "      <td>0.06635</td>\n",
       "      <td>0.04515</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.38280</td>\n",
       "      <td>0.47410</td>\n",
       "      <td>0.49955</td>\n",
       "      <td>0.50775</td>\n",
       "      <td>0.50890</td>\n",
       "      <td>0.24765</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.834221</td>\n",
       "      <td>0.731688</td>\n",
       "      <td>0.337125</td>\n",
       "      <td>0.652436</td>\n",
       "      <td>0.765506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01345</td>\n",
       "      <td>0.02925</td>\n",
       "      <td>0.06315</td>\n",
       "      <td>0.04920</td>\n",
       "      <td>0.12335</td>\n",
       "      <td>0.28515</td>\n",
       "      <td>0.33710</td>\n",
       "      <td>0.39055</td>\n",
       "      <td>0.37655</td>\n",
       "      <td>0.42050</td>\n",
       "      <td>0.23555</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.776236</td>\n",
       "      <td>0.581962</td>\n",
       "      <td>0.247564</td>\n",
       "      <td>0.544852</td>\n",
       "      <td>0.721622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01575</td>\n",
       "      <td>0.02970</td>\n",
       "      <td>0.06900</td>\n",
       "      <td>0.04870</td>\n",
       "      <td>0.13360</td>\n",
       "      <td>0.39940</td>\n",
       "      <td>0.49485</td>\n",
       "      <td>0.52430</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.48935</td>\n",
       "      <td>0.23950</td>\n",
       "      <td>0.1177</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830017</td>\n",
       "      <td>0.746039</td>\n",
       "      <td>0.372872</td>\n",
       "      <td>0.664865</td>\n",
       "      <td>0.767403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152805</th>\n",
       "      <td>1152806</td>\n",
       "      <td>0.03720</td>\n",
       "      <td>0.04660</td>\n",
       "      <td>0.06660</td>\n",
       "      <td>0.08560</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.21200</td>\n",
       "      <td>0.24360</td>\n",
       "      <td>0.26880</td>\n",
       "      <td>0.28690</td>\n",
       "      <td>0.27960</td>\n",
       "      <td>0.28600</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.516930</td>\n",
       "      <td>0.319632</td>\n",
       "      <td>-0.031002</td>\n",
       "      <td>0.321629</td>\n",
       "      <td>0.602862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152806</th>\n",
       "      <td>1152807</td>\n",
       "      <td>0.03840</td>\n",
       "      <td>0.04250</td>\n",
       "      <td>0.07690</td>\n",
       "      <td>0.08000</td>\n",
       "      <td>0.14000</td>\n",
       "      <td>0.25190</td>\n",
       "      <td>0.28530</td>\n",
       "      <td>0.34760</td>\n",
       "      <td>0.33920</td>\n",
       "      <td>0.32180</td>\n",
       "      <td>0.29830</td>\n",
       "      <td>0.1563</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.625819</td>\n",
       "      <td>0.443384</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.432730</td>\n",
       "      <td>0.637691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152807</th>\n",
       "      <td>1152808</td>\n",
       "      <td>0.04280</td>\n",
       "      <td>0.04960</td>\n",
       "      <td>0.06970</td>\n",
       "      <td>0.08880</td>\n",
       "      <td>0.12820</td>\n",
       "      <td>0.18960</td>\n",
       "      <td>0.21990</td>\n",
       "      <td>0.25540</td>\n",
       "      <td>0.25480</td>\n",
       "      <td>0.25390</td>\n",
       "      <td>0.27920</td>\n",
       "      <td>0.1567</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.484021</td>\n",
       "      <td>0.294097</td>\n",
       "      <td>-0.044519</td>\n",
       "      <td>0.296020</td>\n",
       "      <td>0.571209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152808</th>\n",
       "      <td>1152809</td>\n",
       "      <td>0.03170</td>\n",
       "      <td>0.04110</td>\n",
       "      <td>0.06480</td>\n",
       "      <td>0.07660</td>\n",
       "      <td>0.13350</td>\n",
       "      <td>0.23340</td>\n",
       "      <td>0.27290</td>\n",
       "      <td>0.30900</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.29640</td>\n",
       "      <td>0.30290</td>\n",
       "      <td>0.1617</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.602697</td>\n",
       "      <td>0.397850</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>0.393631</td>\n",
       "      <td>0.653291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152809</th>\n",
       "      <td>1152810</td>\n",
       "      <td>0.03540</td>\n",
       "      <td>0.04140</td>\n",
       "      <td>0.08000</td>\n",
       "      <td>0.07390</td>\n",
       "      <td>0.15220</td>\n",
       "      <td>0.28990</td>\n",
       "      <td>0.33570</td>\n",
       "      <td>0.38040</td>\n",
       "      <td>0.39880</td>\n",
       "      <td>0.40650</td>\n",
       "      <td>0.28320</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.674664</td>\n",
       "      <td>0.506344</td>\n",
       "      <td>0.146474</td>\n",
       "      <td>0.481767</td>\n",
       "      <td>0.652476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1152810 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0       B1       B2       B3       B4       B5       B6  \\\n",
       "0                 0  0.00495  0.01885  0.03610  0.05020  0.09065  0.13930   \n",
       "1                 1  0.01040  0.02405  0.03980  0.05720  0.10385  0.16755   \n",
       "2                 2  0.01510  0.02905  0.06635  0.04515  0.12920  0.38280   \n",
       "3                 3  0.01345  0.02925  0.06315  0.04920  0.12335  0.28515   \n",
       "4                 4  0.01575  0.02970  0.06900  0.04870  0.13360  0.39940   \n",
       "...             ...      ...      ...      ...      ...      ...      ...   \n",
       "1152805     1152806  0.03720  0.04660  0.06660  0.08560  0.13300  0.21200   \n",
       "1152806     1152807  0.03840  0.04250  0.07690  0.08000  0.14000  0.25190   \n",
       "1152807     1152808  0.04280  0.04960  0.06970  0.08880  0.12820  0.18960   \n",
       "1152808     1152809  0.03170  0.04110  0.06480  0.07660  0.13350  0.23340   \n",
       "1152809     1152810  0.03540  0.04140  0.08000  0.07390  0.15220  0.28990   \n",
       "\n",
       "              B7       B8      B8A       B9      B11     B12  \\\n",
       "0        0.15855  0.18270  0.19205  0.19175  0.20290  0.1097   \n",
       "1        0.19370  0.21600  0.23420  0.24700  0.22290  0.1204   \n",
       "2        0.47410  0.49955  0.50775  0.50890  0.24765  0.1219   \n",
       "3        0.33710  0.39055  0.37655  0.42050  0.23555  0.1175   \n",
       "4        0.49485  0.52430  0.53900  0.48935  0.23950  0.1177   \n",
       "...          ...      ...      ...      ...      ...     ...   \n",
       "1152805  0.24360  0.26880  0.28690  0.27960  0.28600  0.1640   \n",
       "1152806  0.28530  0.34760  0.33920  0.32180  0.29830  0.1563   \n",
       "1152807  0.21990  0.25540  0.25480  0.25390  0.27920  0.1567   \n",
       "1152808  0.27290  0.30900  0.30940  0.29640  0.30290  0.1617   \n",
       "1152809  0.33570  0.38040  0.39880  0.40650  0.28320  0.1495   \n",
       "\n",
       "         sample_location_id  classes      NDVI       EVI      NDWI      SAVI  \\\n",
       "0                    201701        2  0.568914  0.246737 -0.052386  0.271183   \n",
       "1                    201701        2  0.581259  0.287926 -0.015721  0.308070   \n",
       "2                    201701        2  0.834221  0.731688  0.337125  0.652436   \n",
       "3                    201701        2  0.776236  0.581962  0.247564  0.544852   \n",
       "4                    201701        2  0.830017  0.746039  0.372872  0.664865   \n",
       "...                     ...      ...       ...       ...       ...       ...   \n",
       "1152805              202312        2  0.516930  0.319632 -0.031002  0.321629   \n",
       "1152806              202312        2  0.625819  0.443384  0.076328  0.432730   \n",
       "1152807              202312        2  0.484021  0.294097 -0.044519  0.296020   \n",
       "1152808              202312        2  0.602697  0.397850  0.009969  0.393631   \n",
       "1152809              202312        2  0.674664  0.506344  0.146474  0.481767   \n",
       "\n",
       "            GNDVI  \n",
       "0        0.670018  \n",
       "1        0.688819  \n",
       "2        0.765506  \n",
       "3        0.721622  \n",
       "4        0.767403  \n",
       "...           ...  \n",
       "1152805  0.602862  \n",
       "1152806  0.637691  \n",
       "1152807  0.571209  \n",
       "1152808  0.653291  \n",
       "1152809  0.652476  \n",
       "\n",
       "[1152810 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.read_csv('merged_df.csv')\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming 'class' column to 'classes' to fix python error\n",
    "merged_df = merged_df.rename(columns={'class': 'classes'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, I will make some new dataframes for binary classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a DataFrame with classes 1 and 4\n",
    "class_1_4_df = merged_df[merged_df['classes'].isin([1, 4])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B9</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9842</th>\n",
       "      <td>0.01865</td>\n",
       "      <td>0.05105</td>\n",
       "      <td>0.07580</td>\n",
       "      <td>0.06180</td>\n",
       "      <td>0.12655</td>\n",
       "      <td>0.27940</td>\n",
       "      <td>0.32480</td>\n",
       "      <td>0.35875</td>\n",
       "      <td>0.37050</td>\n",
       "      <td>0.35395</td>\n",
       "      <td>0.20805</td>\n",
       "      <td>0.10675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9843</th>\n",
       "      <td>0.02580</td>\n",
       "      <td>0.05455</td>\n",
       "      <td>0.07065</td>\n",
       "      <td>0.06045</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.26640</td>\n",
       "      <td>0.30535</td>\n",
       "      <td>0.33880</td>\n",
       "      <td>0.34985</td>\n",
       "      <td>0.33795</td>\n",
       "      <td>0.22375</td>\n",
       "      <td>0.11440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9844</th>\n",
       "      <td>0.01355</td>\n",
       "      <td>0.03450</td>\n",
       "      <td>0.06355</td>\n",
       "      <td>0.05075</td>\n",
       "      <td>0.11345</td>\n",
       "      <td>0.24090</td>\n",
       "      <td>0.27965</td>\n",
       "      <td>0.30590</td>\n",
       "      <td>0.32365</td>\n",
       "      <td>0.31530</td>\n",
       "      <td>0.18985</td>\n",
       "      <td>0.10140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>0.02700</td>\n",
       "      <td>0.04475</td>\n",
       "      <td>0.07310</td>\n",
       "      <td>0.07660</td>\n",
       "      <td>0.14820</td>\n",
       "      <td>0.27565</td>\n",
       "      <td>0.32250</td>\n",
       "      <td>0.34800</td>\n",
       "      <td>0.36675</td>\n",
       "      <td>0.36475</td>\n",
       "      <td>0.26760</td>\n",
       "      <td>0.15715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9846</th>\n",
       "      <td>0.02190</td>\n",
       "      <td>0.04735</td>\n",
       "      <td>0.06520</td>\n",
       "      <td>0.05325</td>\n",
       "      <td>0.11545</td>\n",
       "      <td>0.26510</td>\n",
       "      <td>0.30440</td>\n",
       "      <td>0.32650</td>\n",
       "      <td>0.34915</td>\n",
       "      <td>0.35330</td>\n",
       "      <td>0.21820</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107630</th>\n",
       "      <td>0.03940</td>\n",
       "      <td>0.04150</td>\n",
       "      <td>0.06540</td>\n",
       "      <td>0.07980</td>\n",
       "      <td>0.12370</td>\n",
       "      <td>0.19380</td>\n",
       "      <td>0.22340</td>\n",
       "      <td>0.24700</td>\n",
       "      <td>0.26710</td>\n",
       "      <td>0.27200</td>\n",
       "      <td>0.27330</td>\n",
       "      <td>0.15590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107631</th>\n",
       "      <td>0.03630</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.05900</td>\n",
       "      <td>0.07600</td>\n",
       "      <td>0.12830</td>\n",
       "      <td>0.20520</td>\n",
       "      <td>0.23680</td>\n",
       "      <td>0.25780</td>\n",
       "      <td>0.28190</td>\n",
       "      <td>0.29500</td>\n",
       "      <td>0.27540</td>\n",
       "      <td>0.15850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107632</th>\n",
       "      <td>0.02560</td>\n",
       "      <td>0.03560</td>\n",
       "      <td>0.05040</td>\n",
       "      <td>0.06380</td>\n",
       "      <td>0.10790</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.20570</td>\n",
       "      <td>0.22860</td>\n",
       "      <td>0.24280</td>\n",
       "      <td>0.26940</td>\n",
       "      <td>0.27770</td>\n",
       "      <td>0.15700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107633</th>\n",
       "      <td>0.03450</td>\n",
       "      <td>0.04550</td>\n",
       "      <td>0.07100</td>\n",
       "      <td>0.08820</td>\n",
       "      <td>0.13700</td>\n",
       "      <td>0.23200</td>\n",
       "      <td>0.26630</td>\n",
       "      <td>0.28900</td>\n",
       "      <td>0.30960</td>\n",
       "      <td>0.31320</td>\n",
       "      <td>0.25640</td>\n",
       "      <td>0.15010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107634</th>\n",
       "      <td>0.02840</td>\n",
       "      <td>0.04320</td>\n",
       "      <td>0.06640</td>\n",
       "      <td>0.08240</td>\n",
       "      <td>0.14130</td>\n",
       "      <td>0.23620</td>\n",
       "      <td>0.27420</td>\n",
       "      <td>0.28860</td>\n",
       "      <td>0.34640</td>\n",
       "      <td>0.34400</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.16360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744364 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              B1       B2       B3       B4       B5       B6       B7  \\\n",
       "9842     0.01865  0.05105  0.07580  0.06180  0.12655  0.27940  0.32480   \n",
       "9843     0.02580  0.05455  0.07065  0.06045  0.12780  0.26640  0.30535   \n",
       "9844     0.01355  0.03450  0.06355  0.05075  0.11345  0.24090  0.27965   \n",
       "9845     0.02700  0.04475  0.07310  0.07660  0.14820  0.27565  0.32250   \n",
       "9846     0.02190  0.04735  0.06520  0.05325  0.11545  0.26510  0.30440   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "1107630  0.03940  0.04150  0.06540  0.07980  0.12370  0.19380  0.22340   \n",
       "1107631  0.03630  0.03760  0.05900  0.07600  0.12830  0.20520  0.23680   \n",
       "1107632  0.02560  0.03560  0.05040  0.06380  0.10790  0.18100  0.20570   \n",
       "1107633  0.03450  0.04550  0.07100  0.08820  0.13700  0.23200  0.26630   \n",
       "1107634  0.02840  0.04320  0.06640  0.08240  0.14130  0.23620  0.27420   \n",
       "\n",
       "              B8      B8A       B9      B11      B12  classes  \n",
       "9842     0.35875  0.37050  0.35395  0.20805  0.10675        1  \n",
       "9843     0.33880  0.34985  0.33795  0.22375  0.11440        1  \n",
       "9844     0.30590  0.32365  0.31530  0.18985  0.10140        1  \n",
       "9845     0.34800  0.36675  0.36475  0.26760  0.15715        1  \n",
       "9846     0.32650  0.34915  0.35330  0.21820  0.11260        1  \n",
       "...          ...      ...      ...      ...      ...      ...  \n",
       "1107630  0.24700  0.26710  0.27200  0.27330  0.15590        1  \n",
       "1107631  0.25780  0.28190  0.29500  0.27540  0.15850        1  \n",
       "1107632  0.22860  0.24280  0.26940  0.27770  0.15700        1  \n",
       "1107633  0.28900  0.30960  0.31320  0.25640  0.15010        1  \n",
       "1107634  0.28860  0.34640  0.34400  0.30260  0.16360        1  \n",
       "\n",
       "[744364 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the columns you want to keep\n",
    "class_1_4_df = class_1_4_df.loc[:, ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A',\n",
    "                              'B9', 'B11', 'B12', 'classes']]\n",
    "class_1_4_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing train and test sets\n",
    "Starting by shuffling: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B9</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03425</td>\n",
       "      <td>0.03845</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.06870</td>\n",
       "      <td>0.13100</td>\n",
       "      <td>0.20070</td>\n",
       "      <td>0.23280</td>\n",
       "      <td>0.25870</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.26380</td>\n",
       "      <td>0.24960</td>\n",
       "      <td>0.13535</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03250</td>\n",
       "      <td>0.04340</td>\n",
       "      <td>0.0643</td>\n",
       "      <td>0.06380</td>\n",
       "      <td>0.14050</td>\n",
       "      <td>0.26550</td>\n",
       "      <td>0.30340</td>\n",
       "      <td>0.31760</td>\n",
       "      <td>0.35510</td>\n",
       "      <td>0.31620</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.12960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03775</td>\n",
       "      <td>0.05730</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.09515</td>\n",
       "      <td>0.14805</td>\n",
       "      <td>0.22945</td>\n",
       "      <td>0.25975</td>\n",
       "      <td>0.30075</td>\n",
       "      <td>0.29675</td>\n",
       "      <td>0.28945</td>\n",
       "      <td>0.25910</td>\n",
       "      <td>0.14280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03440</td>\n",
       "      <td>0.04540</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.06720</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.30720</td>\n",
       "      <td>0.36230</td>\n",
       "      <td>0.39480</td>\n",
       "      <td>0.41350</td>\n",
       "      <td>0.42180</td>\n",
       "      <td>0.23620</td>\n",
       "      <td>0.12740</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03710</td>\n",
       "      <td>0.04320</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.07140</td>\n",
       "      <td>0.13600</td>\n",
       "      <td>0.27470</td>\n",
       "      <td>0.32090</td>\n",
       "      <td>0.35600</td>\n",
       "      <td>0.36920</td>\n",
       "      <td>0.42830</td>\n",
       "      <td>0.23130</td>\n",
       "      <td>0.12350</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744359</th>\n",
       "      <td>0.03420</td>\n",
       "      <td>0.04950</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>0.06050</td>\n",
       "      <td>0.14080</td>\n",
       "      <td>0.29350</td>\n",
       "      <td>0.34160</td>\n",
       "      <td>0.37720</td>\n",
       "      <td>0.39280</td>\n",
       "      <td>0.36720</td>\n",
       "      <td>0.25400</td>\n",
       "      <td>0.12470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744360</th>\n",
       "      <td>0.03510</td>\n",
       "      <td>0.04450</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.06800</td>\n",
       "      <td>0.11520</td>\n",
       "      <td>0.18780</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.24460</td>\n",
       "      <td>0.25600</td>\n",
       "      <td>0.27930</td>\n",
       "      <td>0.21960</td>\n",
       "      <td>0.11240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744361</th>\n",
       "      <td>0.02590</td>\n",
       "      <td>0.03070</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.04920</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.20140</td>\n",
       "      <td>0.23210</td>\n",
       "      <td>0.25840</td>\n",
       "      <td>0.27360</td>\n",
       "      <td>0.30400</td>\n",
       "      <td>0.21370</td>\n",
       "      <td>0.10680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744362</th>\n",
       "      <td>0.03420</td>\n",
       "      <td>0.04840</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.08080</td>\n",
       "      <td>0.13400</td>\n",
       "      <td>0.19350</td>\n",
       "      <td>0.22380</td>\n",
       "      <td>0.24400</td>\n",
       "      <td>0.26620</td>\n",
       "      <td>0.26820</td>\n",
       "      <td>0.27060</td>\n",
       "      <td>0.15340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744363</th>\n",
       "      <td>0.03520</td>\n",
       "      <td>0.05185</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.07425</td>\n",
       "      <td>0.12295</td>\n",
       "      <td>0.19440</td>\n",
       "      <td>0.21780</td>\n",
       "      <td>0.23920</td>\n",
       "      <td>0.25565</td>\n",
       "      <td>0.25655</td>\n",
       "      <td>0.25175</td>\n",
       "      <td>0.14095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744364 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             B1       B2      B3       B4       B5       B6       B7       B8  \\\n",
       "0       0.03425  0.03845  0.0549  0.06870  0.13100  0.20070  0.23280  0.25870   \n",
       "1       0.03250  0.04340  0.0643  0.06380  0.14050  0.26550  0.30340  0.31760   \n",
       "2       0.03775  0.05730  0.0808  0.09515  0.14805  0.22945  0.25975  0.30075   \n",
       "3       0.03440  0.04540  0.0744  0.06720  0.15140  0.30720  0.36230  0.39480   \n",
       "4       0.03710  0.04320  0.0703  0.07140  0.13600  0.27470  0.32090  0.35600   \n",
       "...         ...      ...     ...      ...      ...      ...      ...      ...   \n",
       "744359  0.03420  0.04950  0.0728  0.06050  0.14080  0.29350  0.34160  0.37720   \n",
       "744360  0.03510  0.04450  0.0628  0.06800  0.11520  0.18780  0.21130  0.24460   \n",
       "744361  0.02590  0.03070  0.0487  0.04920  0.10770  0.20140  0.23210  0.25840   \n",
       "744362  0.03420  0.04840  0.0686  0.08080  0.13400  0.19350  0.22380  0.24400   \n",
       "744363  0.03520  0.05185  0.0675  0.07425  0.12295  0.19440  0.21780  0.23920   \n",
       "\n",
       "            B8A       B9      B11      B12  classes  \n",
       "0       0.27735  0.26380  0.24960  0.13535        4  \n",
       "1       0.35510  0.31620  0.24390  0.12960        1  \n",
       "2       0.29675  0.28945  0.25910  0.14280        1  \n",
       "3       0.41350  0.42180  0.23620  0.12740        1  \n",
       "4       0.36920  0.42830  0.23130  0.12350        1  \n",
       "...         ...      ...      ...      ...      ...  \n",
       "744359  0.39280  0.36720  0.25400  0.12470        1  \n",
       "744360  0.25600  0.27930  0.21960  0.11240        1  \n",
       "744361  0.27360  0.30400  0.21370  0.10680        1  \n",
       "744362  0.26620  0.26820  0.27060  0.15340        1  \n",
       "744363  0.25565  0.25655  0.25175  0.14095        1  \n",
       "\n",
       "[744364 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the DataFrame using a random seed, for example, seed=42\n",
    "class_1_4_df = class_1_4_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "class_1_4_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your features are all columns except 'classes', and 'classes' is the target variable\n",
    "X = class_1_4_df.drop('classes', axis=1)  # Features\n",
    "y = class_1_4_df['classes']  # Target variable\n",
    "\n",
    "# Perform the split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# X_train and y_train will now contain 70% of the data, X_test and y_test will contain 30%\n",
    "# Both splits will have the same proportion of class 0 and 4 as the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 400)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32, log=True)\n",
    "    # Ensuring min_samples_split is an int >= 2\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    # Ensuring min_samples_leaf is a float within (0.0, 0.5], you could also use suggest_int if you want specific integer values\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "\n",
    "    # Initialize the classifier with the current hyperparameters\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth, \n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    # Compute and return the accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-12 15:56:52,307]\u001b[0m A new study created in memory with name: no-name-e8668471-b327-4661-a09c-3a916dbf63b4\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 15:57:59,544]\u001b[0m Trial 0 finished with value: 0.7430925619094533 and parameters: {'n_estimators': 94, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7430925619094533.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:01:02,975]\u001b[0m Trial 1 finished with value: 0.7190273610675743 and parameters: {'n_estimators': 347, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7430925619094533.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:02:45,972]\u001b[0m Trial 2 finished with value: 0.7591733464690341 and parameters: {'n_estimators': 121, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7591733464690341.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:06:44,285]\u001b[0m Trial 3 finished with value: 0.7820787246428731 and parameters: {'n_estimators': 254, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.7820787246428731.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:13:31,325]\u001b[0m Trial 4 finished with value: 0.8199722359052438 and parameters: {'n_estimators': 373, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.8199722359052438.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:15:57,686]\u001b[0m Trial 5 finished with value: 0.9519725941516278 and parameters: {'n_estimators': 75, 'max_depth': 28, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.9519725941516278.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:16:46,495]\u001b[0m Trial 6 finished with value: 0.6929694147149702 and parameters: {'n_estimators': 190, 'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.9519725941516278.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:19:24,547]\u001b[0m Trial 7 finished with value: 0.7297568402668936 and parameters: {'n_estimators': 244, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.9519725941516278.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:23:12,280]\u001b[0m Trial 8 finished with value: 0.7306972370247637 and parameters: {'n_estimators': 352, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.9519725941516278.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:25:25,688]\u001b[0m Trial 9 finished with value: 0.7191393130625587 and parameters: {'n_estimators': 241, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.9519725941516278.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:27:04,281]\u001b[0m Trial 10 finished with value: 0.9563611123550222 and parameters: {'n_estimators': 50, 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9563611123550222.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:28:50,912]\u001b[0m Trial 11 finished with value: 0.9587255384890959 and parameters: {'n_estimators': 54, 'max_depth': 32, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9587255384890959.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:33:40,673]\u001b[0m Trial 12 finished with value: 0.9548743898616273 and parameters: {'n_estimators': 148, 'max_depth': 32, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.9587255384890959.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:35:50,166]\u001b[0m Trial 13 finished with value: 0.9268774349558909 and parameters: {'n_estimators': 74, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9587255384890959.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:37:09,550]\u001b[0m Trial 14 finished with value: 0.8923469616228561 and parameters: {'n_estimators': 53, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.9587255384890959.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:41:39,242]\u001b[0m Trial 15 finished with value: 0.919246786977744 and parameters: {'n_estimators': 159, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.9587255384890959.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:43:24,946]\u001b[0m Trial 16 finished with value: 0.7060006269311719 and parameters: {'n_estimators': 289, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9587255384890959.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:46:02,276]\u001b[0m Trial 17 finished with value: 0.8660427208812861 and parameters: {'n_estimators': 116, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.9587255384890959.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:51:57,659]\u001b[0m Trial 18 finished with value: 0.9460212260982491 and parameters: {'n_estimators': 190, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.9587255384890959.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 16:53:10,344]\u001b[0m Trial 19 finished with value: 0.850767990685594 and parameters: {'n_estimators': 56, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9587255384890959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'n_estimators': 54, 'max_depth': 32, 'min_samples_split': 2, 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)  # Adjust the number of trials as needed\n",
    "\n",
    "print(f\"Best trial: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "Precision: 0.6898636010407122\n",
      "Logistic Regression Accuracy: 0.7049079754601227\n",
      "Recall: 0.7049079754601227\n",
      "F1 Score: 0.6654426381417604\n",
      "Cohen's Kappa: 0.23047738948846375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "log_reg = LogisticRegression(max_iter=1000) # Increase max_iter if convergence warnings occur\n",
    "\n",
    "# Train the classifier on the training set\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "log_reg_predictions = log_reg.predict(X_test)\n",
    "\n",
    "# Predict on the test set\n",
    "lr_predictions = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate metrics, specifying pos_label for binary classification\n",
    "lr_precision = precision_score(y_test, lr_predictions, average='weighted')\n",
    "log_reg_accuracy = accuracy_score(y_test, log_reg_predictions)\n",
    "lr_recall = recall_score(y_test, lr_predictions, average='weighted')\n",
    "lr_f1 = f1_score(y_test, lr_predictions, average='weighted')\n",
    "lr_kappa = cohen_kappa_score(y_test, lr_predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(f\"Precision: {lr_precision}\")\n",
    "print(f'Logistic Regression Accuracy: {log_reg_accuracy}')\n",
    "print(f\"Recall: {lr_recall}\")\n",
    "print(f\"F1 Score: {lr_f1}\")\n",
    "print(f\"Cohen's Kappa: {lr_kappa}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then an RF model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Performance:\n",
      "Precision: 0.9590637156389611\n",
      "Recall: 0.9587255384890959\n",
      "F1 Score: 0.9583607112994191\n",
      "Cohen's Kappa: 0.9058549887875094\n",
      "Optimized RandomForest Accuracy: 0.9587255384890959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Best trial: {'n_estimators': 54, 'max_depth': 32, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
    "\n",
    "# Assuming you have your optimized hyperparameters, for example:\n",
    "optimized_hyperparameters = {\n",
    "    'n_estimators': 54,\n",
    "    'max_depth': 32,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 2, \n",
    "    # Include other hyperparameters as necessary\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with optimized hyperparameters\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=optimized_hyperparameters['n_estimators'],\n",
    "    max_depth=optimized_hyperparameters['max_depth'],\n",
    "    min_samples_split=optimized_hyperparameters['min_samples_split'],\n",
    "    min_samples_leaf=optimized_hyperparameters['min_samples_leaf'],\n",
    "    random_state=42  # Ensuring reproducibility\n",
    ")\n",
    "\n",
    "# Train the classifier on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Compute and display the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "rf_precision = precision_score(y_test, predictions, average='weighted')\n",
    "rf_recall = recall_score(y_test, predictions, average='weighted')\n",
    "rf_f1 = f1_score(y_test, predictions, average='weighted')\n",
    "rf_kappa = cohen_kappa_score(y_test, predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(\"RandomForest Performance:\")\n",
    "print(f\"Precision: {rf_precision}\")\n",
    "print(f\"Recall: {rf_recall}\")\n",
    "print(f\"F1 Score: {rf_f1}\")\n",
    "print(f\"Cohen's Kappa: {rf_kappa}\")\n",
    "print(f'Optimized RandomForest Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You'll also want to output an aggregated prediction confusion matrix (from the cross-validation), preferably as a seaborn (sns) figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming predictions, y_test are already defined\n",
    "\n",
    "# Compute the normalized confusion matrix\n",
    "cm_normalized = confusion_matrix(y_test, predictions, labels=[1, 4], normalize='true')\n",
    "\n",
    "# Visualize the normalized confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt=\".2%\", cmap=\"Greens\", xticklabels=[1, 4], yticklabels=[1, 4])\n",
    "plt.title('Normalised Confusion Matrix Round 4 No. 7')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Save the figure with a white background\n",
    "plt.savefig('round4_no7_matrix.png', bbox_inches='tight', pad_inches=0, facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming clf is your trained RandomForestClassifier model\n",
    "# and X_test, y_test are your test datasets\n",
    "\n",
    "result = permutation_importance(clf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Sorting features by importance\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "bp = ax.boxplot(result.importances[sorted_idx].T, vert=False, labels=X_test.columns[sorted_idx],\n",
    "                patch_artist=True,  # To fill with color\n",
    "                )\n",
    "\n",
    "# Customizing the boxplot color to dark green\n",
    "for box in bp['boxes']:\n",
    "    # Change box color\n",
    "    box.set(color='darkgreen', linewidth=2)  # Box edge color\n",
    "    box.set(facecolor='darkgreen')  # Box fill color\n",
    "\n",
    "# Optionally, customize whiskers, fliers, caps, and medians if needed\n",
    "for whisker in bp['whiskers']:\n",
    "    whisker.set(color='darkgreen', linewidth=2)\n",
    "for cap in bp['caps']:\n",
    "    cap.set(color='darkgreen', linewidth=2)\n",
    "for median in bp['medians']:\n",
    "    median.set(color='gold', linewidth=2)  # Making the median stand out\n",
    "\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_title(\"Permutation Importances Round 4 No. 7 (test set)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('r4_n7_features.png', bbox_inches='tight', pad_inches=0, facecolor='white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
