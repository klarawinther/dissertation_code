{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation notebook\n",
    "Round 5 no. 9 binary classification based on class 3 (bare peat) and class 4 (restored) from the original dataset, and trained bands and VIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B9</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>sample_location_id</th>\n",
       "      <th>classes</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>SAVI</th>\n",
       "      <th>GNDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00495</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.03610</td>\n",
       "      <td>0.05020</td>\n",
       "      <td>0.09065</td>\n",
       "      <td>0.13930</td>\n",
       "      <td>0.15855</td>\n",
       "      <td>0.18270</td>\n",
       "      <td>0.19205</td>\n",
       "      <td>0.19175</td>\n",
       "      <td>0.20290</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.568914</td>\n",
       "      <td>0.246737</td>\n",
       "      <td>-0.052386</td>\n",
       "      <td>0.271183</td>\n",
       "      <td>0.670018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01040</td>\n",
       "      <td>0.02405</td>\n",
       "      <td>0.03980</td>\n",
       "      <td>0.05720</td>\n",
       "      <td>0.10385</td>\n",
       "      <td>0.16755</td>\n",
       "      <td>0.19370</td>\n",
       "      <td>0.21600</td>\n",
       "      <td>0.23420</td>\n",
       "      <td>0.24700</td>\n",
       "      <td>0.22290</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.581259</td>\n",
       "      <td>0.287926</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>0.308070</td>\n",
       "      <td>0.688819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01510</td>\n",
       "      <td>0.02905</td>\n",
       "      <td>0.06635</td>\n",
       "      <td>0.04515</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.38280</td>\n",
       "      <td>0.47410</td>\n",
       "      <td>0.49955</td>\n",
       "      <td>0.50775</td>\n",
       "      <td>0.50890</td>\n",
       "      <td>0.24765</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.834221</td>\n",
       "      <td>0.731688</td>\n",
       "      <td>0.337125</td>\n",
       "      <td>0.652436</td>\n",
       "      <td>0.765506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01345</td>\n",
       "      <td>0.02925</td>\n",
       "      <td>0.06315</td>\n",
       "      <td>0.04920</td>\n",
       "      <td>0.12335</td>\n",
       "      <td>0.28515</td>\n",
       "      <td>0.33710</td>\n",
       "      <td>0.39055</td>\n",
       "      <td>0.37655</td>\n",
       "      <td>0.42050</td>\n",
       "      <td>0.23555</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.776236</td>\n",
       "      <td>0.581962</td>\n",
       "      <td>0.247564</td>\n",
       "      <td>0.544852</td>\n",
       "      <td>0.721622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01575</td>\n",
       "      <td>0.02970</td>\n",
       "      <td>0.06900</td>\n",
       "      <td>0.04870</td>\n",
       "      <td>0.13360</td>\n",
       "      <td>0.39940</td>\n",
       "      <td>0.49485</td>\n",
       "      <td>0.52430</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.48935</td>\n",
       "      <td>0.23950</td>\n",
       "      <td>0.1177</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830017</td>\n",
       "      <td>0.746039</td>\n",
       "      <td>0.372872</td>\n",
       "      <td>0.664865</td>\n",
       "      <td>0.767403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152805</th>\n",
       "      <td>1152806</td>\n",
       "      <td>0.03720</td>\n",
       "      <td>0.04660</td>\n",
       "      <td>0.06660</td>\n",
       "      <td>0.08560</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.21200</td>\n",
       "      <td>0.24360</td>\n",
       "      <td>0.26880</td>\n",
       "      <td>0.28690</td>\n",
       "      <td>0.27960</td>\n",
       "      <td>0.28600</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.516930</td>\n",
       "      <td>0.319632</td>\n",
       "      <td>-0.031002</td>\n",
       "      <td>0.321629</td>\n",
       "      <td>0.602862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152806</th>\n",
       "      <td>1152807</td>\n",
       "      <td>0.03840</td>\n",
       "      <td>0.04250</td>\n",
       "      <td>0.07690</td>\n",
       "      <td>0.08000</td>\n",
       "      <td>0.14000</td>\n",
       "      <td>0.25190</td>\n",
       "      <td>0.28530</td>\n",
       "      <td>0.34760</td>\n",
       "      <td>0.33920</td>\n",
       "      <td>0.32180</td>\n",
       "      <td>0.29830</td>\n",
       "      <td>0.1563</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.625819</td>\n",
       "      <td>0.443384</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.432730</td>\n",
       "      <td>0.637691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152807</th>\n",
       "      <td>1152808</td>\n",
       "      <td>0.04280</td>\n",
       "      <td>0.04960</td>\n",
       "      <td>0.06970</td>\n",
       "      <td>0.08880</td>\n",
       "      <td>0.12820</td>\n",
       "      <td>0.18960</td>\n",
       "      <td>0.21990</td>\n",
       "      <td>0.25540</td>\n",
       "      <td>0.25480</td>\n",
       "      <td>0.25390</td>\n",
       "      <td>0.27920</td>\n",
       "      <td>0.1567</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.484021</td>\n",
       "      <td>0.294097</td>\n",
       "      <td>-0.044519</td>\n",
       "      <td>0.296020</td>\n",
       "      <td>0.571209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152808</th>\n",
       "      <td>1152809</td>\n",
       "      <td>0.03170</td>\n",
       "      <td>0.04110</td>\n",
       "      <td>0.06480</td>\n",
       "      <td>0.07660</td>\n",
       "      <td>0.13350</td>\n",
       "      <td>0.23340</td>\n",
       "      <td>0.27290</td>\n",
       "      <td>0.30900</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.29640</td>\n",
       "      <td>0.30290</td>\n",
       "      <td>0.1617</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.602697</td>\n",
       "      <td>0.397850</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>0.393631</td>\n",
       "      <td>0.653291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152809</th>\n",
       "      <td>1152810</td>\n",
       "      <td>0.03540</td>\n",
       "      <td>0.04140</td>\n",
       "      <td>0.08000</td>\n",
       "      <td>0.07390</td>\n",
       "      <td>0.15220</td>\n",
       "      <td>0.28990</td>\n",
       "      <td>0.33570</td>\n",
       "      <td>0.38040</td>\n",
       "      <td>0.39880</td>\n",
       "      <td>0.40650</td>\n",
       "      <td>0.28320</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.674664</td>\n",
       "      <td>0.506344</td>\n",
       "      <td>0.146474</td>\n",
       "      <td>0.481767</td>\n",
       "      <td>0.652476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1152810 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0       B1       B2       B3       B4       B5       B6  \\\n",
       "0                 0  0.00495  0.01885  0.03610  0.05020  0.09065  0.13930   \n",
       "1                 1  0.01040  0.02405  0.03980  0.05720  0.10385  0.16755   \n",
       "2                 2  0.01510  0.02905  0.06635  0.04515  0.12920  0.38280   \n",
       "3                 3  0.01345  0.02925  0.06315  0.04920  0.12335  0.28515   \n",
       "4                 4  0.01575  0.02970  0.06900  0.04870  0.13360  0.39940   \n",
       "...             ...      ...      ...      ...      ...      ...      ...   \n",
       "1152805     1152806  0.03720  0.04660  0.06660  0.08560  0.13300  0.21200   \n",
       "1152806     1152807  0.03840  0.04250  0.07690  0.08000  0.14000  0.25190   \n",
       "1152807     1152808  0.04280  0.04960  0.06970  0.08880  0.12820  0.18960   \n",
       "1152808     1152809  0.03170  0.04110  0.06480  0.07660  0.13350  0.23340   \n",
       "1152809     1152810  0.03540  0.04140  0.08000  0.07390  0.15220  0.28990   \n",
       "\n",
       "              B7       B8      B8A       B9      B11     B12  \\\n",
       "0        0.15855  0.18270  0.19205  0.19175  0.20290  0.1097   \n",
       "1        0.19370  0.21600  0.23420  0.24700  0.22290  0.1204   \n",
       "2        0.47410  0.49955  0.50775  0.50890  0.24765  0.1219   \n",
       "3        0.33710  0.39055  0.37655  0.42050  0.23555  0.1175   \n",
       "4        0.49485  0.52430  0.53900  0.48935  0.23950  0.1177   \n",
       "...          ...      ...      ...      ...      ...     ...   \n",
       "1152805  0.24360  0.26880  0.28690  0.27960  0.28600  0.1640   \n",
       "1152806  0.28530  0.34760  0.33920  0.32180  0.29830  0.1563   \n",
       "1152807  0.21990  0.25540  0.25480  0.25390  0.27920  0.1567   \n",
       "1152808  0.27290  0.30900  0.30940  0.29640  0.30290  0.1617   \n",
       "1152809  0.33570  0.38040  0.39880  0.40650  0.28320  0.1495   \n",
       "\n",
       "         sample_location_id  classes      NDVI       EVI      NDWI      SAVI  \\\n",
       "0                    201701        2  0.568914  0.246737 -0.052386  0.271183   \n",
       "1                    201701        2  0.581259  0.287926 -0.015721  0.308070   \n",
       "2                    201701        2  0.834221  0.731688  0.337125  0.652436   \n",
       "3                    201701        2  0.776236  0.581962  0.247564  0.544852   \n",
       "4                    201701        2  0.830017  0.746039  0.372872  0.664865   \n",
       "...                     ...      ...       ...       ...       ...       ...   \n",
       "1152805              202312        2  0.516930  0.319632 -0.031002  0.321629   \n",
       "1152806              202312        2  0.625819  0.443384  0.076328  0.432730   \n",
       "1152807              202312        2  0.484021  0.294097 -0.044519  0.296020   \n",
       "1152808              202312        2  0.602697  0.397850  0.009969  0.393631   \n",
       "1152809              202312        2  0.674664  0.506344  0.146474  0.481767   \n",
       "\n",
       "            GNDVI  \n",
       "0        0.670018  \n",
       "1        0.688819  \n",
       "2        0.765506  \n",
       "3        0.721622  \n",
       "4        0.767403  \n",
       "...           ...  \n",
       "1152805  0.602862  \n",
       "1152806  0.637691  \n",
       "1152807  0.571209  \n",
       "1152808  0.653291  \n",
       "1152809  0.652476  \n",
       "\n",
       "[1152810 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.read_csv('merged_df.csv')\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B9</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>sample_location_id</th>\n",
       "      <th>classes</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>SAVI</th>\n",
       "      <th>GNDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00495</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.03610</td>\n",
       "      <td>0.05020</td>\n",
       "      <td>0.09065</td>\n",
       "      <td>0.13930</td>\n",
       "      <td>0.15855</td>\n",
       "      <td>0.18270</td>\n",
       "      <td>0.19205</td>\n",
       "      <td>0.19175</td>\n",
       "      <td>0.20290</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.568914</td>\n",
       "      <td>0.246737</td>\n",
       "      <td>-0.052386</td>\n",
       "      <td>0.271183</td>\n",
       "      <td>0.670018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01040</td>\n",
       "      <td>0.02405</td>\n",
       "      <td>0.03980</td>\n",
       "      <td>0.05720</td>\n",
       "      <td>0.10385</td>\n",
       "      <td>0.16755</td>\n",
       "      <td>0.19370</td>\n",
       "      <td>0.21600</td>\n",
       "      <td>0.23420</td>\n",
       "      <td>0.24700</td>\n",
       "      <td>0.22290</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.581259</td>\n",
       "      <td>0.287926</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>0.308070</td>\n",
       "      <td>0.688819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01510</td>\n",
       "      <td>0.02905</td>\n",
       "      <td>0.06635</td>\n",
       "      <td>0.04515</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.38280</td>\n",
       "      <td>0.47410</td>\n",
       "      <td>0.49955</td>\n",
       "      <td>0.50775</td>\n",
       "      <td>0.50890</td>\n",
       "      <td>0.24765</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.834221</td>\n",
       "      <td>0.731688</td>\n",
       "      <td>0.337125</td>\n",
       "      <td>0.652436</td>\n",
       "      <td>0.765506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01345</td>\n",
       "      <td>0.02925</td>\n",
       "      <td>0.06315</td>\n",
       "      <td>0.04920</td>\n",
       "      <td>0.12335</td>\n",
       "      <td>0.28515</td>\n",
       "      <td>0.33710</td>\n",
       "      <td>0.39055</td>\n",
       "      <td>0.37655</td>\n",
       "      <td>0.42050</td>\n",
       "      <td>0.23555</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.776236</td>\n",
       "      <td>0.581962</td>\n",
       "      <td>0.247564</td>\n",
       "      <td>0.544852</td>\n",
       "      <td>0.721622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01575</td>\n",
       "      <td>0.02970</td>\n",
       "      <td>0.06900</td>\n",
       "      <td>0.04870</td>\n",
       "      <td>0.13360</td>\n",
       "      <td>0.39940</td>\n",
       "      <td>0.49485</td>\n",
       "      <td>0.52430</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.48935</td>\n",
       "      <td>0.23950</td>\n",
       "      <td>0.1177</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830017</td>\n",
       "      <td>0.746039</td>\n",
       "      <td>0.372872</td>\n",
       "      <td>0.664865</td>\n",
       "      <td>0.767403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152805</th>\n",
       "      <td>1152806</td>\n",
       "      <td>0.03720</td>\n",
       "      <td>0.04660</td>\n",
       "      <td>0.06660</td>\n",
       "      <td>0.08560</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.21200</td>\n",
       "      <td>0.24360</td>\n",
       "      <td>0.26880</td>\n",
       "      <td>0.28690</td>\n",
       "      <td>0.27960</td>\n",
       "      <td>0.28600</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.516930</td>\n",
       "      <td>0.319632</td>\n",
       "      <td>-0.031002</td>\n",
       "      <td>0.321629</td>\n",
       "      <td>0.602862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152806</th>\n",
       "      <td>1152807</td>\n",
       "      <td>0.03840</td>\n",
       "      <td>0.04250</td>\n",
       "      <td>0.07690</td>\n",
       "      <td>0.08000</td>\n",
       "      <td>0.14000</td>\n",
       "      <td>0.25190</td>\n",
       "      <td>0.28530</td>\n",
       "      <td>0.34760</td>\n",
       "      <td>0.33920</td>\n",
       "      <td>0.32180</td>\n",
       "      <td>0.29830</td>\n",
       "      <td>0.1563</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.625819</td>\n",
       "      <td>0.443384</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.432730</td>\n",
       "      <td>0.637691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152807</th>\n",
       "      <td>1152808</td>\n",
       "      <td>0.04280</td>\n",
       "      <td>0.04960</td>\n",
       "      <td>0.06970</td>\n",
       "      <td>0.08880</td>\n",
       "      <td>0.12820</td>\n",
       "      <td>0.18960</td>\n",
       "      <td>0.21990</td>\n",
       "      <td>0.25540</td>\n",
       "      <td>0.25480</td>\n",
       "      <td>0.25390</td>\n",
       "      <td>0.27920</td>\n",
       "      <td>0.1567</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.484021</td>\n",
       "      <td>0.294097</td>\n",
       "      <td>-0.044519</td>\n",
       "      <td>0.296020</td>\n",
       "      <td>0.571209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152808</th>\n",
       "      <td>1152809</td>\n",
       "      <td>0.03170</td>\n",
       "      <td>0.04110</td>\n",
       "      <td>0.06480</td>\n",
       "      <td>0.07660</td>\n",
       "      <td>0.13350</td>\n",
       "      <td>0.23340</td>\n",
       "      <td>0.27290</td>\n",
       "      <td>0.30900</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.29640</td>\n",
       "      <td>0.30290</td>\n",
       "      <td>0.1617</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.602697</td>\n",
       "      <td>0.397850</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>0.393631</td>\n",
       "      <td>0.653291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152809</th>\n",
       "      <td>1152810</td>\n",
       "      <td>0.03540</td>\n",
       "      <td>0.04140</td>\n",
       "      <td>0.08000</td>\n",
       "      <td>0.07390</td>\n",
       "      <td>0.15220</td>\n",
       "      <td>0.28990</td>\n",
       "      <td>0.33570</td>\n",
       "      <td>0.38040</td>\n",
       "      <td>0.39880</td>\n",
       "      <td>0.40650</td>\n",
       "      <td>0.28320</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.674664</td>\n",
       "      <td>0.506344</td>\n",
       "      <td>0.146474</td>\n",
       "      <td>0.481767</td>\n",
       "      <td>0.652476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1152810 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0       B1       B2       B3       B4       B5       B6  \\\n",
       "0                 0  0.00495  0.01885  0.03610  0.05020  0.09065  0.13930   \n",
       "1                 1  0.01040  0.02405  0.03980  0.05720  0.10385  0.16755   \n",
       "2                 2  0.01510  0.02905  0.06635  0.04515  0.12920  0.38280   \n",
       "3                 3  0.01345  0.02925  0.06315  0.04920  0.12335  0.28515   \n",
       "4                 4  0.01575  0.02970  0.06900  0.04870  0.13360  0.39940   \n",
       "...             ...      ...      ...      ...      ...      ...      ...   \n",
       "1152805     1152806  0.03720  0.04660  0.06660  0.08560  0.13300  0.21200   \n",
       "1152806     1152807  0.03840  0.04250  0.07690  0.08000  0.14000  0.25190   \n",
       "1152807     1152808  0.04280  0.04960  0.06970  0.08880  0.12820  0.18960   \n",
       "1152808     1152809  0.03170  0.04110  0.06480  0.07660  0.13350  0.23340   \n",
       "1152809     1152810  0.03540  0.04140  0.08000  0.07390  0.15220  0.28990   \n",
       "\n",
       "              B7       B8      B8A       B9      B11     B12  \\\n",
       "0        0.15855  0.18270  0.19205  0.19175  0.20290  0.1097   \n",
       "1        0.19370  0.21600  0.23420  0.24700  0.22290  0.1204   \n",
       "2        0.47410  0.49955  0.50775  0.50890  0.24765  0.1219   \n",
       "3        0.33710  0.39055  0.37655  0.42050  0.23555  0.1175   \n",
       "4        0.49485  0.52430  0.53900  0.48935  0.23950  0.1177   \n",
       "...          ...      ...      ...      ...      ...     ...   \n",
       "1152805  0.24360  0.26880  0.28690  0.27960  0.28600  0.1640   \n",
       "1152806  0.28530  0.34760  0.33920  0.32180  0.29830  0.1563   \n",
       "1152807  0.21990  0.25540  0.25480  0.25390  0.27920  0.1567   \n",
       "1152808  0.27290  0.30900  0.30940  0.29640  0.30290  0.1617   \n",
       "1152809  0.33570  0.38040  0.39880  0.40650  0.28320  0.1495   \n",
       "\n",
       "         sample_location_id  classes      NDVI       EVI      NDWI      SAVI  \\\n",
       "0                    201701        2  0.568914  0.246737 -0.052386  0.271183   \n",
       "1                    201701        2  0.581259  0.287926 -0.015721  0.308070   \n",
       "2                    201701        2  0.834221  0.731688  0.337125  0.652436   \n",
       "3                    201701        2  0.776236  0.581962  0.247564  0.544852   \n",
       "4                    201701        2  0.830017  0.746039  0.372872  0.664865   \n",
       "...                     ...      ...       ...       ...       ...       ...   \n",
       "1152805              202312        2  0.516930  0.319632 -0.031002  0.321629   \n",
       "1152806              202312        2  0.625819  0.443384  0.076328  0.432730   \n",
       "1152807              202312        2  0.484021  0.294097 -0.044519  0.296020   \n",
       "1152808              202312        2  0.602697  0.397850  0.009969  0.393631   \n",
       "1152809              202312        2  0.674664  0.506344  0.146474  0.481767   \n",
       "\n",
       "            GNDVI  \n",
       "0        0.670018  \n",
       "1        0.688819  \n",
       "2        0.765506  \n",
       "3        0.721622  \n",
       "4        0.767403  \n",
       "...           ...  \n",
       "1152805  0.602862  \n",
       "1152806  0.637691  \n",
       "1152807  0.571209  \n",
       "1152808  0.653291  \n",
       "1152809  0.652476  \n",
       "\n",
       "[1152810 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['NDVI'] = (merged_df['B8'] - merged_df['B4']) / (merged_df['B8'] + merged_df['B4'])\n",
    "\n",
    "# EVI is an optimized vegetation index designed to enhance the vegetation signal with improved sensitivity in high biomass regions\n",
    "# It's calculated using the Red (B4), Near-Infrared (B8 or B5), and Blue (B2) bands.\n",
    "merged_df['EVI'] = 2.5 * (merged_df['B8'] - merged_df['B4']) / (merged_df['B8'] + 6 * merged_df['B4'] - 7.5 * merged_df['B2'] + 1)\n",
    "\n",
    "# NDWI is used to monitor changes in water content of leaves\n",
    "# It is typically calculated using the Near-Infrared (B8 or B5) and Short-Wave Infrared (B11 or B6) bands.\n",
    "merged_df['NDWI'] = (merged_df['B8'] - merged_df['B11']) / (merged_df['B8'] + merged_df['B11'])\n",
    "\n",
    "# SAVI is a modification of NDVI to correct for the influence of soil brightness\n",
    "# The standard value of L in the SAVI formula is 0.5.\n",
    "L = 0.5  # soil brightness correction factor\n",
    "merged_df['SAVI'] = ((merged_df['B8'] - merged_df['B4']) / (merged_df['B8'] + merged_df['B4'] + L)) * (1 + L)\n",
    "\n",
    "# GNDVI is used to estimate vegetation health\n",
    "# It's calculated using the Near-Infrared (B8 or B5) and Green (B3) bands.\n",
    "merged_df['GNDVI'] = (merged_df['B8'] - merged_df['B3']) / (merged_df['B8'] + merged_df['B3'])\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming 'class' column to 'classes' to fix python error\n",
    "merged_df = merged_df.rename(columns={'class': 'classes'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, I will make some new dataframes for binary classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create a DataFrame with classes 3 and 4\n",
    "class_3_4_df = merged_df[merged_df['classes'].isin([3, 4])]\n",
    "\n",
    "# Remember to reset the index if needed, for example:\n",
    "# binary_df = binary_df.reset_index(drop=True)\n",
    "\n",
    "# Note: Using .loc for assignment avoids SettingWithCopyWarning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B9</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>classes</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>SAVI</th>\n",
       "      <th>GNDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35750</th>\n",
       "      <td>0.02970</td>\n",
       "      <td>0.02580</td>\n",
       "      <td>0.04230</td>\n",
       "      <td>0.07455</td>\n",
       "      <td>0.09715</td>\n",
       "      <td>0.11690</td>\n",
       "      <td>0.14080</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.18725</td>\n",
       "      <td>0.18210</td>\n",
       "      <td>0.30790</td>\n",
       "      <td>0.23750</td>\n",
       "      <td>3</td>\n",
       "      <td>0.349334</td>\n",
       "      <td>0.142094</td>\n",
       "      <td>-0.331459</td>\n",
       "      <td>0.164678</td>\n",
       "      <td>0.570340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35751</th>\n",
       "      <td>0.01420</td>\n",
       "      <td>0.01870</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>0.04320</td>\n",
       "      <td>0.05080</td>\n",
       "      <td>0.06020</td>\n",
       "      <td>0.07470</td>\n",
       "      <td>0.09140</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.10710</td>\n",
       "      <td>0.31970</td>\n",
       "      <td>0.25230</td>\n",
       "      <td>3</td>\n",
       "      <td>0.358098</td>\n",
       "      <td>0.099558</td>\n",
       "      <td>-0.555339</td>\n",
       "      <td>0.113930</td>\n",
       "      <td>0.585429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35752</th>\n",
       "      <td>0.02725</td>\n",
       "      <td>0.02280</td>\n",
       "      <td>0.03020</td>\n",
       "      <td>0.05910</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.08120</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.11940</td>\n",
       "      <td>0.14680</td>\n",
       "      <td>0.14200</td>\n",
       "      <td>0.35250</td>\n",
       "      <td>0.26460</td>\n",
       "      <td>3</td>\n",
       "      <td>0.337815</td>\n",
       "      <td>0.115695</td>\n",
       "      <td>-0.493961</td>\n",
       "      <td>0.133309</td>\n",
       "      <td>0.596257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35753</th>\n",
       "      <td>0.02280</td>\n",
       "      <td>0.02395</td>\n",
       "      <td>0.03355</td>\n",
       "      <td>0.05455</td>\n",
       "      <td>0.06725</td>\n",
       "      <td>0.08180</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.14380</td>\n",
       "      <td>0.13440</td>\n",
       "      <td>0.35790</td>\n",
       "      <td>0.28405</td>\n",
       "      <td>3</td>\n",
       "      <td>0.417667</td>\n",
       "      <td>0.152775</td>\n",
       "      <td>-0.458732</td>\n",
       "      <td>0.170765</td>\n",
       "      <td>0.596634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35754</th>\n",
       "      <td>0.02380</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.03590</td>\n",
       "      <td>0.06600</td>\n",
       "      <td>0.08410</td>\n",
       "      <td>0.09725</td>\n",
       "      <td>0.12025</td>\n",
       "      <td>0.14195</td>\n",
       "      <td>0.15835</td>\n",
       "      <td>0.15760</td>\n",
       "      <td>0.28895</td>\n",
       "      <td>0.21005</td>\n",
       "      <td>3</td>\n",
       "      <td>0.365232</td>\n",
       "      <td>0.140445</td>\n",
       "      <td>-0.341146</td>\n",
       "      <td>0.160922</td>\n",
       "      <td>0.596289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973048</th>\n",
       "      <td>0.04320</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>0.10860</td>\n",
       "      <td>0.10840</td>\n",
       "      <td>0.14960</td>\n",
       "      <td>0.24210</td>\n",
       "      <td>0.26960</td>\n",
       "      <td>0.27300</td>\n",
       "      <td>0.30400</td>\n",
       "      <td>0.33030</td>\n",
       "      <td>0.26350</td>\n",
       "      <td>0.17790</td>\n",
       "      <td>4</td>\n",
       "      <td>0.431568</td>\n",
       "      <td>0.309538</td>\n",
       "      <td>0.017707</td>\n",
       "      <td>0.280123</td>\n",
       "      <td>0.430818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973049</th>\n",
       "      <td>0.03785</td>\n",
       "      <td>0.04785</td>\n",
       "      <td>0.06970</td>\n",
       "      <td>0.06560</td>\n",
       "      <td>0.12645</td>\n",
       "      <td>0.25330</td>\n",
       "      <td>0.29020</td>\n",
       "      <td>0.29550</td>\n",
       "      <td>0.32395</td>\n",
       "      <td>0.36635</td>\n",
       "      <td>0.25945</td>\n",
       "      <td>0.14200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.636666</td>\n",
       "      <td>0.432070</td>\n",
       "      <td>0.064961</td>\n",
       "      <td>0.400476</td>\n",
       "      <td>0.618291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973050</th>\n",
       "      <td>0.03790</td>\n",
       "      <td>0.04110</td>\n",
       "      <td>0.06890</td>\n",
       "      <td>0.06720</td>\n",
       "      <td>0.13390</td>\n",
       "      <td>0.26230</td>\n",
       "      <td>0.30250</td>\n",
       "      <td>0.31360</td>\n",
       "      <td>0.32760</td>\n",
       "      <td>0.34050</td>\n",
       "      <td>0.25300</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>4</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.437329</td>\n",
       "      <td>0.106954</td>\n",
       "      <td>0.419619</td>\n",
       "      <td>0.639739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973051</th>\n",
       "      <td>0.04520</td>\n",
       "      <td>0.03395</td>\n",
       "      <td>0.05660</td>\n",
       "      <td>0.04715</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.22845</td>\n",
       "      <td>0.26085</td>\n",
       "      <td>0.28060</td>\n",
       "      <td>0.29645</td>\n",
       "      <td>0.29380</td>\n",
       "      <td>0.21370</td>\n",
       "      <td>0.11775</td>\n",
       "      <td>4</td>\n",
       "      <td>0.712281</td>\n",
       "      <td>0.445898</td>\n",
       "      <td>0.135343</td>\n",
       "      <td>0.423044</td>\n",
       "      <td>0.664294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973052</th>\n",
       "      <td>0.03830</td>\n",
       "      <td>0.04920</td>\n",
       "      <td>0.07680</td>\n",
       "      <td>0.08620</td>\n",
       "      <td>0.14490</td>\n",
       "      <td>0.27630</td>\n",
       "      <td>0.31810</td>\n",
       "      <td>0.32760</td>\n",
       "      <td>0.36500</td>\n",
       "      <td>0.34880</td>\n",
       "      <td>0.28350</td>\n",
       "      <td>0.16180</td>\n",
       "      <td>4</td>\n",
       "      <td>0.583374</td>\n",
       "      <td>0.408931</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>0.396257</td>\n",
       "      <td>0.620178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305877 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             B1       B2       B3       B4       B5       B6       B7  \\\n",
       "35750   0.02970  0.02580  0.04230  0.07455  0.09715  0.11690  0.14080   \n",
       "35751   0.01420  0.01870  0.02390  0.04320  0.05080  0.06020  0.07470   \n",
       "35752   0.02725  0.02280  0.03020  0.05910  0.07400  0.08120  0.10220   \n",
       "35753   0.02280  0.02395  0.03355  0.05455  0.06725  0.08180  0.10450   \n",
       "35754   0.02380  0.02480  0.03590  0.06600  0.08410  0.09725  0.12025   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "973048  0.04320  0.07920  0.10860  0.10840  0.14960  0.24210  0.26960   \n",
       "973049  0.03785  0.04785  0.06970  0.06560  0.12645  0.25330  0.29020   \n",
       "973050  0.03790  0.04110  0.06890  0.06720  0.13390  0.26230  0.30250   \n",
       "973051  0.04520  0.03395  0.05660  0.04715  0.10640  0.22845  0.26085   \n",
       "973052  0.03830  0.04920  0.07680  0.08620  0.14490  0.27630  0.31810   \n",
       "\n",
       "             B8      B8A       B9      B11      B12  classes      NDVI  \\\n",
       "35750   0.15460  0.18725  0.18210  0.30790  0.23750        3  0.349334   \n",
       "35751   0.09140  0.10240  0.10710  0.31970  0.25230        3  0.358098   \n",
       "35752   0.11940  0.14680  0.14200  0.35250  0.26460        3  0.337815   \n",
       "35753   0.13280  0.14380  0.13440  0.35790  0.28405        3  0.417667   \n",
       "35754   0.14195  0.15835  0.15760  0.28895  0.21005        3  0.365232   \n",
       "...         ...      ...      ...      ...      ...      ...       ...   \n",
       "973048  0.27300  0.30400  0.33030  0.26350  0.17790        4  0.431568   \n",
       "973049  0.29550  0.32395  0.36635  0.25945  0.14200        4  0.636666   \n",
       "973050  0.31360  0.32760  0.34050  0.25300  0.14900        4  0.647059   \n",
       "973051  0.28060  0.29645  0.29380  0.21370  0.11775        4  0.712281   \n",
       "973052  0.32760  0.36500  0.34880  0.28350  0.16180        4  0.583374   \n",
       "\n",
       "             EVI      NDWI      SAVI     GNDVI  \n",
       "35750   0.142094 -0.331459  0.164678  0.570340  \n",
       "35751   0.099558 -0.555339  0.113930  0.585429  \n",
       "35752   0.115695 -0.493961  0.133309  0.596257  \n",
       "35753   0.152775 -0.458732  0.170765  0.596634  \n",
       "35754   0.140445 -0.341146  0.160922  0.596289  \n",
       "...          ...       ...       ...       ...  \n",
       "973048  0.309538  0.017707  0.280123  0.430818  \n",
       "973049  0.432070  0.064961  0.400476  0.618291  \n",
       "973050  0.437329  0.106954  0.419619  0.639739  \n",
       "973051  0.445898  0.135343  0.423044  0.664294  \n",
       "973052  0.408931  0.072165  0.396257  0.620178  \n",
       "\n",
       "[305877 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the columns you want to keep\n",
    "class_3_4_df = class_3_4_df.loc[:, ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A',\n",
    "                              'B9', 'B11', 'B12', 'classes', 'NDVI', 'EVI', 'NDWI', 'SAVI', 'GNDVI']]\n",
    "class_3_4_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing train and test sets\n",
    "\n",
    "Starting by shuffling dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B9</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>classes</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>SAVI</th>\n",
       "      <th>GNDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.07330</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.08920</td>\n",
       "      <td>0.1599</td>\n",
       "      <td>0.21980</td>\n",
       "      <td>0.24960</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.29300</td>\n",
       "      <td>0.31260</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>4</td>\n",
       "      <td>0.520430</td>\n",
       "      <td>0.381628</td>\n",
       "      <td>0.062559</td>\n",
       "      <td>0.333028</td>\n",
       "      <td>0.501859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.04500</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>0.06720</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.28760</td>\n",
       "      <td>0.33790</td>\n",
       "      <td>0.3388</td>\n",
       "      <td>0.38820</td>\n",
       "      <td>0.34330</td>\n",
       "      <td>0.2761</td>\n",
       "      <td>0.14260</td>\n",
       "      <td>4</td>\n",
       "      <td>0.668966</td>\n",
       "      <td>0.483446</td>\n",
       "      <td>0.101968</td>\n",
       "      <td>0.449669</td>\n",
       "      <td>0.646259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.05010</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>0.10120</td>\n",
       "      <td>0.1503</td>\n",
       "      <td>0.21470</td>\n",
       "      <td>0.24200</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.29580</td>\n",
       "      <td>0.31110</td>\n",
       "      <td>0.2949</td>\n",
       "      <td>0.17330</td>\n",
       "      <td>4</td>\n",
       "      <td>0.479692</td>\n",
       "      <td>0.307059</td>\n",
       "      <td>-0.012185</td>\n",
       "      <td>0.314848</td>\n",
       "      <td>0.588300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.05465</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.08235</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.21885</td>\n",
       "      <td>0.24865</td>\n",
       "      <td>0.2826</td>\n",
       "      <td>0.29130</td>\n",
       "      <td>0.28510</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.15555</td>\n",
       "      <td>4</td>\n",
       "      <td>0.548705</td>\n",
       "      <td>0.366269</td>\n",
       "      <td>0.041651</td>\n",
       "      <td>0.347274</td>\n",
       "      <td>0.577009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.02440</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.05660</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.08740</td>\n",
       "      <td>0.10810</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.14960</td>\n",
       "      <td>0.15610</td>\n",
       "      <td>0.3499</td>\n",
       "      <td>0.27660</td>\n",
       "      <td>3</td>\n",
       "      <td>0.394004</td>\n",
       "      <td>0.142990</td>\n",
       "      <td>-0.457613</td>\n",
       "      <td>0.160745</td>\n",
       "      <td>0.595588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305872</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.03140</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.04830</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.37820</td>\n",
       "      <td>0.4132</td>\n",
       "      <td>0.41920</td>\n",
       "      <td>0.45330</td>\n",
       "      <td>0.2147</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>4</td>\n",
       "      <td>0.790683</td>\n",
       "      <td>0.621635</td>\n",
       "      <td>0.316133</td>\n",
       "      <td>0.569267</td>\n",
       "      <td>0.731769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305873</th>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.06470</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.09300</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.24270</td>\n",
       "      <td>0.27510</td>\n",
       "      <td>0.2986</td>\n",
       "      <td>0.31230</td>\n",
       "      <td>0.30670</td>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.14920</td>\n",
       "      <td>4</td>\n",
       "      <td>0.525026</td>\n",
       "      <td>0.374813</td>\n",
       "      <td>0.040781</td>\n",
       "      <td>0.345895</td>\n",
       "      <td>0.542355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305874</th>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.03520</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.05060</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.25670</td>\n",
       "      <td>0.29450</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>0.33220</td>\n",
       "      <td>0.31890</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.10110</td>\n",
       "      <td>4</td>\n",
       "      <td>0.716209</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.214527</td>\n",
       "      <td>0.447233</td>\n",
       "      <td>0.673503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305875</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.03840</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.05470</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.28070</td>\n",
       "      <td>0.31925</td>\n",
       "      <td>0.3496</td>\n",
       "      <td>0.35985</td>\n",
       "      <td>0.36015</td>\n",
       "      <td>0.2377</td>\n",
       "      <td>0.12200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.729409</td>\n",
       "      <td>0.530472</td>\n",
       "      <td>0.190533</td>\n",
       "      <td>0.489163</td>\n",
       "      <td>0.696264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305876</th>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.02840</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>0.04990</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.31120</td>\n",
       "      <td>0.37350</td>\n",
       "      <td>0.4120</td>\n",
       "      <td>0.40850</td>\n",
       "      <td>0.40100</td>\n",
       "      <td>0.2259</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>4</td>\n",
       "      <td>0.783936</td>\n",
       "      <td>0.604144</td>\n",
       "      <td>0.291739</td>\n",
       "      <td>0.564664</td>\n",
       "      <td>0.743177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305877 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            B1       B2      B3       B4      B5       B6       B7      B8  \\\n",
       "0       0.0495  0.07330  0.0938  0.08920  0.1599  0.21980  0.24960  0.2828   \n",
       "1       0.0353  0.04500  0.0728  0.06720  0.1296  0.28760  0.33790  0.3388   \n",
       "2       0.0340  0.05010  0.0746  0.10120  0.1503  0.21470  0.24200  0.2878   \n",
       "3       0.0494  0.05465  0.0758  0.08235  0.1313  0.21885  0.24865  0.2826   \n",
       "4       0.0207  0.02440  0.0330  0.05660  0.0755  0.08740  0.10810  0.1302   \n",
       "...        ...      ...     ...      ...     ...      ...      ...     ...   \n",
       "305872  0.0164  0.03140  0.0640  0.04830  0.1276  0.30640  0.37820  0.4132   \n",
       "305873  0.0456  0.06470  0.0886  0.09300  0.1601  0.24270  0.27510  0.2986   \n",
       "305874  0.0276  0.03520  0.0597  0.05060  0.1238  0.25670  0.29450  0.3060   \n",
       "305875  0.0323  0.03840  0.0626  0.05470  0.1276  0.28070  0.31925  0.3496   \n",
       "305876  0.0170  0.02840  0.0607  0.04990  0.1289  0.31120  0.37350  0.4120   \n",
       "\n",
       "            B8A       B9     B11      B12  classes      NDVI       EVI  \\\n",
       "0       0.29300  0.31260  0.2495  0.12940        4  0.520430  0.381628   \n",
       "1       0.38820  0.34330  0.2761  0.14260        4  0.668966  0.483446   \n",
       "2       0.29580  0.31110  0.2949  0.17330        4  0.479692  0.307059   \n",
       "3       0.29130  0.28510  0.2600  0.15555        4  0.548705  0.366269   \n",
       "4       0.14960  0.15610  0.3499  0.27660        3  0.394004  0.142990   \n",
       "...         ...      ...     ...      ...      ...       ...       ...   \n",
       "305872  0.41920  0.45330  0.2147  0.10220        4  0.790683  0.621635   \n",
       "305873  0.31230  0.30670  0.2752  0.14920        4  0.525026  0.374813   \n",
       "305874  0.33220  0.31890  0.1979  0.10110        4  0.716209  0.474510   \n",
       "305875  0.35985  0.36015  0.2377  0.12200        4  0.729409  0.530472   \n",
       "305876  0.40850  0.40100  0.2259  0.11210        4  0.783936  0.604144   \n",
       "\n",
       "            NDWI      SAVI     GNDVI  \n",
       "0       0.062559  0.333028  0.501859  \n",
       "1       0.101968  0.449669  0.646259  \n",
       "2      -0.012185  0.314848  0.588300  \n",
       "3       0.041651  0.347274  0.577009  \n",
       "4      -0.457613  0.160745  0.595588  \n",
       "...          ...       ...       ...  \n",
       "305872  0.316133  0.569267  0.731769  \n",
       "305873  0.040781  0.345895  0.542355  \n",
       "305874  0.214527  0.447233  0.673503  \n",
       "305875  0.190533  0.489163  0.696264  \n",
       "305876  0.291739  0.564664  0.743177  \n",
       "\n",
       "[305877 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the DataFrame using a random seed, for example, seed=42\n",
    "class_3_4_df = class_3_4_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "class_3_4_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then making splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your features are all columns except 'classes', and 'classes' is the target variable\n",
    "X = class_3_4_df.drop('classes', axis=1)  # Features\n",
    "y = class_3_4_df['classes']  # Target variable\n",
    "\n",
    "# Perform the split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# X_train and y_train will now contain 70% of the data, X_test and y_test will contain 30%\n",
    "# Both splits will have the same proportion of class 0 and 4 as the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN values check for class_3_4_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any NaN values in class_3_4_df? False\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check for any NaN values in the DataFrame\n",
    "nan_exists = class_3_4_df.isnull().values.any()\n",
    "\n",
    "# Print result\n",
    "print(f\"Are there any NaN values in class_3_4_df? {nan_exists}\")\n",
    "\n",
    "# Get the count of NaNs in each column\n",
    "nan_counts = class_3_4_df.isnull().sum()\n",
    "\n",
    "# Print columns with NaN counts greater than 0\n",
    "print(nan_counts[nan_counts > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 400)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32, log=True)\n",
    "    # Ensuring min_samples_split is an int >= 2\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    # Ensuring min_samples_leaf is a float within (0.0, 0.5], you could also use suggest_int if you want specific integer values\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "\n",
    "    # Initialize the classifier with the current hyperparameters\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth, \n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    # Compute and return the accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-12 17:44:47,816]\u001b[0m A new study created in memory with name: no-name-f7558693-a63a-43c2-a141-32e1e9537522\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:46:02,619]\u001b[0m Trial 0 finished with value: 0.9593304563881261 and parameters: {'n_estimators': 112, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.9593304563881261.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:47:01,270]\u001b[0m Trial 1 finished with value: 0.9293731746654461 and parameters: {'n_estimators': 223, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.9593304563881261.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:48:40,064]\u001b[0m Trial 2 finished with value: 0.9497188439911076 and parameters: {'n_estimators': 219, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9593304563881261.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:50:54,446]\u001b[0m Trial 3 finished with value: 0.9532496403818491 and parameters: {'n_estimators': 275, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.9593304563881261.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:51:45,360]\u001b[0m Trial 4 finished with value: 0.9060960725338912 and parameters: {'n_estimators': 391, 'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.9593304563881261.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:53:23,724]\u001b[0m Trial 5 finished with value: 0.935236040277233 and parameters: {'n_estimators': 339, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.9593304563881261.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:55:20,923]\u001b[0m Trial 6 finished with value: 0.9413495488426834 and parameters: {'n_estimators': 344, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.9593304563881261.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:57:12,788]\u001b[0m Trial 7 finished with value: 0.9596900745390349 and parameters: {'n_estimators': 201, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.9596900745390349.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:58:30,117]\u001b[0m Trial 8 finished with value: 0.9784773985440913 and parameters: {'n_estimators': 100, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 8 with value: 0.9784773985440913.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:59:57,671]\u001b[0m Trial 9 finished with value: 0.9455341964168955 and parameters: {'n_estimators': 235, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 8 with value: 0.9784773985440913.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 18:00:42,707]\u001b[0m Trial 10 finished with value: 0.9787825290963776 and parameters: {'n_estimators': 55, 'max_depth': 31, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9787825290963776.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 18:02:00,167]\u001b[0m Trial 11 finished with value: 0.9789568894119698 and parameters: {'n_estimators': 50, 'max_depth': 31, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9789568894119698.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 18:03:03,590]\u001b[0m Trial 12 finished with value: 0.9787280414977552 and parameters: {'n_estimators': 58, 'max_depth': 32, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9789568894119698.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 18:04:51,079]\u001b[0m Trial 13 finished with value: 0.9753934004620548 and parameters: {'n_estimators': 146, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9789568894119698.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 18:05:49,122]\u001b[0m Trial 14 finished with value: 0.9750119872716969 and parameters: {'n_estimators': 72, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.9789568894119698.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 18:07:58,564]\u001b[0m Trial 15 finished with value: 0.9762434070005667 and parameters: {'n_estimators': 157, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9789568894119698.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 18:08:44,113]\u001b[0m Trial 16 finished with value: 0.9767555904276187 and parameters: {'n_estimators': 58, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.9789568894119698.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 18:10:17,015]\u001b[0m Trial 17 finished with value: 0.9691164291007367 and parameters: {'n_estimators': 148, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.9789568894119698.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 18:10:34,633]\u001b[0m Trial 18 finished with value: 0.9172006451331677 and parameters: {'n_estimators': 104, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9789568894119698.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 18:12:29,587]\u001b[0m Trial 19 finished with value: 0.9777363672028246 and parameters: {'n_estimators': 162, 'max_depth': 24, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.9789568894119698.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'n_estimators': 50, 'max_depth': 31, 'min_samples_split': 10, 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)  # Adjust the number of trials as needed\n",
    "\n",
    "print(f\"Best trial: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First using a logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "Precision: 0.9278560662479737\n",
      "Logistic Regression Accuracy: 0.9257660956366331\n",
      "Recall: 0.9257660956366331\n",
      "F1 Score: 0.9194576053424838\n",
      "Cohen's Kappa: 0.7152541875542819\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "log_reg = LogisticRegression(max_iter=1000) # Increase max_iter if convergence warnings occur\n",
    "\n",
    "# Train the classifier on the training set\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "log_reg_predictions = log_reg.predict(X_test)\n",
    "\n",
    "# Predict on the test set\n",
    "lr_predictions = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate metrics, specifying pos_label for binary classification\n",
    "lr_precision = precision_score(y_test, lr_predictions, average='weighted')\n",
    "log_reg_accuracy = accuracy_score(y_test, log_reg_predictions)\n",
    "lr_recall = recall_score(y_test, lr_predictions, average='weighted')\n",
    "lr_f1 = f1_score(y_test, lr_predictions, average='weighted')\n",
    "lr_kappa = cohen_kappa_score(y_test, lr_predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(f\"Precision: {lr_precision}\")\n",
    "print(f'Logistic Regression Accuracy: {log_reg_accuracy}')\n",
    "print(f\"Recall: {lr_recall}\")\n",
    "print(f\"F1 Score: {lr_f1}\")\n",
    "print(f\"Cohen's Kappa: {lr_kappa}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then an RF model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Performance:\n",
      "Precision: 0.9790699285034524\n",
      "Recall: 0.9789568894119698\n",
      "F1 Score: 0.9785830511797309\n",
      "Cohen's Kappa: 0.9275871398059148\n",
      "Optimized RandomForest Accuracy: 0.9789568894119698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Best trial: {'n_estimators': 50, 'max_depth': 31, 'min_samples_split': 10, 'min_samples_leaf': 2}\n",
    "\n",
    "# Assuming you have your optimized hyperparameters, for example:\n",
    "optimized_hyperparameters = {\n",
    "    'n_estimators': 50,\n",
    "    'max_depth': 31,\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 2, \n",
    "    # Include other hyperparameters as necessary\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with optimized hyperparameters\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=optimized_hyperparameters['n_estimators'],\n",
    "    max_depth=optimized_hyperparameters['max_depth'],\n",
    "    min_samples_split=optimized_hyperparameters['min_samples_split'],\n",
    "    min_samples_leaf=optimized_hyperparameters['min_samples_leaf'],\n",
    "    random_state=42  # Ensuring reproducibility\n",
    ")\n",
    "\n",
    "# Train the classifier on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Compute and display the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "rf_precision = precision_score(y_test, predictions, average='weighted')\n",
    "rf_recall = recall_score(y_test, predictions, average='weighted')\n",
    "rf_f1 = f1_score(y_test, predictions, average='weighted')\n",
    "rf_kappa = cohen_kappa_score(y_test, predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(\"RandomForest Performance:\")\n",
    "print(f\"Precision: {rf_precision}\")\n",
    "print(f\"Recall: {rf_recall}\")\n",
    "print(f\"F1 Score: {rf_f1}\")\n",
    "print(f\"Cohen's Kappa: {rf_kappa}\")\n",
    "print(f'Optimized RandomForest Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You'll also want to output an aggregated prediction confusion matrix (from the cross-validation), preferably as a seaborn (sns) figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming predictions, y_test are already defined\n",
    "\n",
    "# Compute the normalized confusion matrix\n",
    "cm_normalized = confusion_matrix(y_test, predictions, labels=[3, 4], normalize='true')\n",
    "\n",
    "# Visualize the normalized confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt=\".2%\", cmap=\"Blues\", xticklabels=[3, 4], yticklabels=[3, 4])\n",
    "plt.title('Normalised Confusion Matrix Round 5 No. 10')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Save the figure with a white background\n",
    "plt.savefig('round5_no10_matrix.png', bbox_inches='tight', pad_inches=0, facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming clf is your trained RandomForestClassifier model\n",
    "# and X_test, y_test are your test datasets\n",
    "\n",
    "result = permutation_importance(clf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Sorting features by importance\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "bp = ax.boxplot(result.importances[sorted_idx].T, vert=False, labels=X_test.columns[sorted_idx],\n",
    "                patch_artist=True,  # To fill with color\n",
    "                )\n",
    "\n",
    "# Customizing the boxplot color to dark blue\n",
    "for box in bp['boxes']:\n",
    "    # Change box color\n",
    "    box.set(color='darkblue', linewidth=2)  # Box edge color\n",
    "    box.set(facecolor='darkblue')  # Box fill color\n",
    "\n",
    "# Optionally, customize whiskers, fliers, caps, and medians if needed\n",
    "for whisker in bp['whiskers']:\n",
    "    whisker.set(color='darkblue', linewidth=2)\n",
    "for cap in bp['caps']:\n",
    "    cap.set(color='darkblue', linewidth=2)\n",
    "for median in bp['medians']:\n",
    "    median.set(color='gold', linewidth=2)  # Making the median stand out\n",
    "\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_title(\"Permutation Importances Round 5 No. 10 (test set)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('r5_n10_features.png', bbox_inches='tight', pad_inches=0, facecolor='white')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
