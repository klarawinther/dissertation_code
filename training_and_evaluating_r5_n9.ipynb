{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation notebook\n",
    "Round 5 no. 9 binary classification based on class 3 (bare peat) and class 4 (restored) from the original dataset, and trained on bands only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B9</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>sample_location_id</th>\n",
       "      <th>classes</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>SAVI</th>\n",
       "      <th>GNDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00495</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.03610</td>\n",
       "      <td>0.05020</td>\n",
       "      <td>0.09065</td>\n",
       "      <td>0.13930</td>\n",
       "      <td>0.15855</td>\n",
       "      <td>0.18270</td>\n",
       "      <td>0.19205</td>\n",
       "      <td>0.19175</td>\n",
       "      <td>0.20290</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.568914</td>\n",
       "      <td>0.246737</td>\n",
       "      <td>-0.052386</td>\n",
       "      <td>0.271183</td>\n",
       "      <td>0.670018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01040</td>\n",
       "      <td>0.02405</td>\n",
       "      <td>0.03980</td>\n",
       "      <td>0.05720</td>\n",
       "      <td>0.10385</td>\n",
       "      <td>0.16755</td>\n",
       "      <td>0.19370</td>\n",
       "      <td>0.21600</td>\n",
       "      <td>0.23420</td>\n",
       "      <td>0.24700</td>\n",
       "      <td>0.22290</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.581259</td>\n",
       "      <td>0.287926</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>0.308070</td>\n",
       "      <td>0.688819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01510</td>\n",
       "      <td>0.02905</td>\n",
       "      <td>0.06635</td>\n",
       "      <td>0.04515</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.38280</td>\n",
       "      <td>0.47410</td>\n",
       "      <td>0.49955</td>\n",
       "      <td>0.50775</td>\n",
       "      <td>0.50890</td>\n",
       "      <td>0.24765</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.834221</td>\n",
       "      <td>0.731688</td>\n",
       "      <td>0.337125</td>\n",
       "      <td>0.652436</td>\n",
       "      <td>0.765506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01345</td>\n",
       "      <td>0.02925</td>\n",
       "      <td>0.06315</td>\n",
       "      <td>0.04920</td>\n",
       "      <td>0.12335</td>\n",
       "      <td>0.28515</td>\n",
       "      <td>0.33710</td>\n",
       "      <td>0.39055</td>\n",
       "      <td>0.37655</td>\n",
       "      <td>0.42050</td>\n",
       "      <td>0.23555</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.776236</td>\n",
       "      <td>0.581962</td>\n",
       "      <td>0.247564</td>\n",
       "      <td>0.544852</td>\n",
       "      <td>0.721622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01575</td>\n",
       "      <td>0.02970</td>\n",
       "      <td>0.06900</td>\n",
       "      <td>0.04870</td>\n",
       "      <td>0.13360</td>\n",
       "      <td>0.39940</td>\n",
       "      <td>0.49485</td>\n",
       "      <td>0.52430</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.48935</td>\n",
       "      <td>0.23950</td>\n",
       "      <td>0.1177</td>\n",
       "      <td>201701</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830017</td>\n",
       "      <td>0.746039</td>\n",
       "      <td>0.372872</td>\n",
       "      <td>0.664865</td>\n",
       "      <td>0.767403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152805</th>\n",
       "      <td>1152806</td>\n",
       "      <td>0.03720</td>\n",
       "      <td>0.04660</td>\n",
       "      <td>0.06660</td>\n",
       "      <td>0.08560</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.21200</td>\n",
       "      <td>0.24360</td>\n",
       "      <td>0.26880</td>\n",
       "      <td>0.28690</td>\n",
       "      <td>0.27960</td>\n",
       "      <td>0.28600</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.516930</td>\n",
       "      <td>0.319632</td>\n",
       "      <td>-0.031002</td>\n",
       "      <td>0.321629</td>\n",
       "      <td>0.602862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152806</th>\n",
       "      <td>1152807</td>\n",
       "      <td>0.03840</td>\n",
       "      <td>0.04250</td>\n",
       "      <td>0.07690</td>\n",
       "      <td>0.08000</td>\n",
       "      <td>0.14000</td>\n",
       "      <td>0.25190</td>\n",
       "      <td>0.28530</td>\n",
       "      <td>0.34760</td>\n",
       "      <td>0.33920</td>\n",
       "      <td>0.32180</td>\n",
       "      <td>0.29830</td>\n",
       "      <td>0.1563</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.625819</td>\n",
       "      <td>0.443384</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.432730</td>\n",
       "      <td>0.637691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152807</th>\n",
       "      <td>1152808</td>\n",
       "      <td>0.04280</td>\n",
       "      <td>0.04960</td>\n",
       "      <td>0.06970</td>\n",
       "      <td>0.08880</td>\n",
       "      <td>0.12820</td>\n",
       "      <td>0.18960</td>\n",
       "      <td>0.21990</td>\n",
       "      <td>0.25540</td>\n",
       "      <td>0.25480</td>\n",
       "      <td>0.25390</td>\n",
       "      <td>0.27920</td>\n",
       "      <td>0.1567</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.484021</td>\n",
       "      <td>0.294097</td>\n",
       "      <td>-0.044519</td>\n",
       "      <td>0.296020</td>\n",
       "      <td>0.571209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152808</th>\n",
       "      <td>1152809</td>\n",
       "      <td>0.03170</td>\n",
       "      <td>0.04110</td>\n",
       "      <td>0.06480</td>\n",
       "      <td>0.07660</td>\n",
       "      <td>0.13350</td>\n",
       "      <td>0.23340</td>\n",
       "      <td>0.27290</td>\n",
       "      <td>0.30900</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.29640</td>\n",
       "      <td>0.30290</td>\n",
       "      <td>0.1617</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.602697</td>\n",
       "      <td>0.397850</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>0.393631</td>\n",
       "      <td>0.653291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152809</th>\n",
       "      <td>1152810</td>\n",
       "      <td>0.03540</td>\n",
       "      <td>0.04140</td>\n",
       "      <td>0.08000</td>\n",
       "      <td>0.07390</td>\n",
       "      <td>0.15220</td>\n",
       "      <td>0.28990</td>\n",
       "      <td>0.33570</td>\n",
       "      <td>0.38040</td>\n",
       "      <td>0.39880</td>\n",
       "      <td>0.40650</td>\n",
       "      <td>0.28320</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>202312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.674664</td>\n",
       "      <td>0.506344</td>\n",
       "      <td>0.146474</td>\n",
       "      <td>0.481767</td>\n",
       "      <td>0.652476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1152810 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0       B1       B2       B3       B4       B5       B6  \\\n",
       "0                 0  0.00495  0.01885  0.03610  0.05020  0.09065  0.13930   \n",
       "1                 1  0.01040  0.02405  0.03980  0.05720  0.10385  0.16755   \n",
       "2                 2  0.01510  0.02905  0.06635  0.04515  0.12920  0.38280   \n",
       "3                 3  0.01345  0.02925  0.06315  0.04920  0.12335  0.28515   \n",
       "4                 4  0.01575  0.02970  0.06900  0.04870  0.13360  0.39940   \n",
       "...             ...      ...      ...      ...      ...      ...      ...   \n",
       "1152805     1152806  0.03720  0.04660  0.06660  0.08560  0.13300  0.21200   \n",
       "1152806     1152807  0.03840  0.04250  0.07690  0.08000  0.14000  0.25190   \n",
       "1152807     1152808  0.04280  0.04960  0.06970  0.08880  0.12820  0.18960   \n",
       "1152808     1152809  0.03170  0.04110  0.06480  0.07660  0.13350  0.23340   \n",
       "1152809     1152810  0.03540  0.04140  0.08000  0.07390  0.15220  0.28990   \n",
       "\n",
       "              B7       B8      B8A       B9      B11     B12  \\\n",
       "0        0.15855  0.18270  0.19205  0.19175  0.20290  0.1097   \n",
       "1        0.19370  0.21600  0.23420  0.24700  0.22290  0.1204   \n",
       "2        0.47410  0.49955  0.50775  0.50890  0.24765  0.1219   \n",
       "3        0.33710  0.39055  0.37655  0.42050  0.23555  0.1175   \n",
       "4        0.49485  0.52430  0.53900  0.48935  0.23950  0.1177   \n",
       "...          ...      ...      ...      ...      ...     ...   \n",
       "1152805  0.24360  0.26880  0.28690  0.27960  0.28600  0.1640   \n",
       "1152806  0.28530  0.34760  0.33920  0.32180  0.29830  0.1563   \n",
       "1152807  0.21990  0.25540  0.25480  0.25390  0.27920  0.1567   \n",
       "1152808  0.27290  0.30900  0.30940  0.29640  0.30290  0.1617   \n",
       "1152809  0.33570  0.38040  0.39880  0.40650  0.28320  0.1495   \n",
       "\n",
       "         sample_location_id  classes      NDVI       EVI      NDWI      SAVI  \\\n",
       "0                    201701        2  0.568914  0.246737 -0.052386  0.271183   \n",
       "1                    201701        2  0.581259  0.287926 -0.015721  0.308070   \n",
       "2                    201701        2  0.834221  0.731688  0.337125  0.652436   \n",
       "3                    201701        2  0.776236  0.581962  0.247564  0.544852   \n",
       "4                    201701        2  0.830017  0.746039  0.372872  0.664865   \n",
       "...                     ...      ...       ...       ...       ...       ...   \n",
       "1152805              202312        2  0.516930  0.319632 -0.031002  0.321629   \n",
       "1152806              202312        2  0.625819  0.443384  0.076328  0.432730   \n",
       "1152807              202312        2  0.484021  0.294097 -0.044519  0.296020   \n",
       "1152808              202312        2  0.602697  0.397850  0.009969  0.393631   \n",
       "1152809              202312        2  0.674664  0.506344  0.146474  0.481767   \n",
       "\n",
       "            GNDVI  \n",
       "0        0.670018  \n",
       "1        0.688819  \n",
       "2        0.765506  \n",
       "3        0.721622  \n",
       "4        0.767403  \n",
       "...           ...  \n",
       "1152805  0.602862  \n",
       "1152806  0.637691  \n",
       "1152807  0.571209  \n",
       "1152808  0.653291  \n",
       "1152809  0.652476  \n",
       "\n",
       "[1152810 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.read_csv('merged_df.csv')\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming 'class' column to 'classes' to fix python error\n",
    "merged_df = merged_df.rename(columns={'class': 'classes'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, I will make some new dataframes for binary classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create a DataFrame with classes 3 and 4\n",
    "class_3_4_df = merged_df[merged_df['classes'].isin([3, 4])]\n",
    "\n",
    "# Remember to reset the index if needed, for example:\n",
    "# binary_df = binary_df.reset_index(drop=True)\n",
    "\n",
    "# Note: Using .loc for assignment avoids SettingWithCopyWarning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B9</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35750</th>\n",
       "      <td>0.02970</td>\n",
       "      <td>0.02580</td>\n",
       "      <td>0.04230</td>\n",
       "      <td>0.07455</td>\n",
       "      <td>0.09715</td>\n",
       "      <td>0.11690</td>\n",
       "      <td>0.14080</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.18725</td>\n",
       "      <td>0.18210</td>\n",
       "      <td>0.30790</td>\n",
       "      <td>0.23750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35751</th>\n",
       "      <td>0.01420</td>\n",
       "      <td>0.01870</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>0.04320</td>\n",
       "      <td>0.05080</td>\n",
       "      <td>0.06020</td>\n",
       "      <td>0.07470</td>\n",
       "      <td>0.09140</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.10710</td>\n",
       "      <td>0.31970</td>\n",
       "      <td>0.25230</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35752</th>\n",
       "      <td>0.02725</td>\n",
       "      <td>0.02280</td>\n",
       "      <td>0.03020</td>\n",
       "      <td>0.05910</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.08120</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.11940</td>\n",
       "      <td>0.14680</td>\n",
       "      <td>0.14200</td>\n",
       "      <td>0.35250</td>\n",
       "      <td>0.26460</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35753</th>\n",
       "      <td>0.02280</td>\n",
       "      <td>0.02395</td>\n",
       "      <td>0.03355</td>\n",
       "      <td>0.05455</td>\n",
       "      <td>0.06725</td>\n",
       "      <td>0.08180</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.14380</td>\n",
       "      <td>0.13440</td>\n",
       "      <td>0.35790</td>\n",
       "      <td>0.28405</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35754</th>\n",
       "      <td>0.02380</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.03590</td>\n",
       "      <td>0.06600</td>\n",
       "      <td>0.08410</td>\n",
       "      <td>0.09725</td>\n",
       "      <td>0.12025</td>\n",
       "      <td>0.14195</td>\n",
       "      <td>0.15835</td>\n",
       "      <td>0.15760</td>\n",
       "      <td>0.28895</td>\n",
       "      <td>0.21005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973048</th>\n",
       "      <td>0.04320</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>0.10860</td>\n",
       "      <td>0.10840</td>\n",
       "      <td>0.14960</td>\n",
       "      <td>0.24210</td>\n",
       "      <td>0.26960</td>\n",
       "      <td>0.27300</td>\n",
       "      <td>0.30400</td>\n",
       "      <td>0.33030</td>\n",
       "      <td>0.26350</td>\n",
       "      <td>0.17790</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973049</th>\n",
       "      <td>0.03785</td>\n",
       "      <td>0.04785</td>\n",
       "      <td>0.06970</td>\n",
       "      <td>0.06560</td>\n",
       "      <td>0.12645</td>\n",
       "      <td>0.25330</td>\n",
       "      <td>0.29020</td>\n",
       "      <td>0.29550</td>\n",
       "      <td>0.32395</td>\n",
       "      <td>0.36635</td>\n",
       "      <td>0.25945</td>\n",
       "      <td>0.14200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973050</th>\n",
       "      <td>0.03790</td>\n",
       "      <td>0.04110</td>\n",
       "      <td>0.06890</td>\n",
       "      <td>0.06720</td>\n",
       "      <td>0.13390</td>\n",
       "      <td>0.26230</td>\n",
       "      <td>0.30250</td>\n",
       "      <td>0.31360</td>\n",
       "      <td>0.32760</td>\n",
       "      <td>0.34050</td>\n",
       "      <td>0.25300</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973051</th>\n",
       "      <td>0.04520</td>\n",
       "      <td>0.03395</td>\n",
       "      <td>0.05660</td>\n",
       "      <td>0.04715</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.22845</td>\n",
       "      <td>0.26085</td>\n",
       "      <td>0.28060</td>\n",
       "      <td>0.29645</td>\n",
       "      <td>0.29380</td>\n",
       "      <td>0.21370</td>\n",
       "      <td>0.11775</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973052</th>\n",
       "      <td>0.03830</td>\n",
       "      <td>0.04920</td>\n",
       "      <td>0.07680</td>\n",
       "      <td>0.08620</td>\n",
       "      <td>0.14490</td>\n",
       "      <td>0.27630</td>\n",
       "      <td>0.31810</td>\n",
       "      <td>0.32760</td>\n",
       "      <td>0.36500</td>\n",
       "      <td>0.34880</td>\n",
       "      <td>0.28350</td>\n",
       "      <td>0.16180</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305877 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             B1       B2       B3       B4       B5       B6       B7  \\\n",
       "35750   0.02970  0.02580  0.04230  0.07455  0.09715  0.11690  0.14080   \n",
       "35751   0.01420  0.01870  0.02390  0.04320  0.05080  0.06020  0.07470   \n",
       "35752   0.02725  0.02280  0.03020  0.05910  0.07400  0.08120  0.10220   \n",
       "35753   0.02280  0.02395  0.03355  0.05455  0.06725  0.08180  0.10450   \n",
       "35754   0.02380  0.02480  0.03590  0.06600  0.08410  0.09725  0.12025   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "973048  0.04320  0.07920  0.10860  0.10840  0.14960  0.24210  0.26960   \n",
       "973049  0.03785  0.04785  0.06970  0.06560  0.12645  0.25330  0.29020   \n",
       "973050  0.03790  0.04110  0.06890  0.06720  0.13390  0.26230  0.30250   \n",
       "973051  0.04520  0.03395  0.05660  0.04715  0.10640  0.22845  0.26085   \n",
       "973052  0.03830  0.04920  0.07680  0.08620  0.14490  0.27630  0.31810   \n",
       "\n",
       "             B8      B8A       B9      B11      B12  classes  \n",
       "35750   0.15460  0.18725  0.18210  0.30790  0.23750        3  \n",
       "35751   0.09140  0.10240  0.10710  0.31970  0.25230        3  \n",
       "35752   0.11940  0.14680  0.14200  0.35250  0.26460        3  \n",
       "35753   0.13280  0.14380  0.13440  0.35790  0.28405        3  \n",
       "35754   0.14195  0.15835  0.15760  0.28895  0.21005        3  \n",
       "...         ...      ...      ...      ...      ...      ...  \n",
       "973048  0.27300  0.30400  0.33030  0.26350  0.17790        4  \n",
       "973049  0.29550  0.32395  0.36635  0.25945  0.14200        4  \n",
       "973050  0.31360  0.32760  0.34050  0.25300  0.14900        4  \n",
       "973051  0.28060  0.29645  0.29380  0.21370  0.11775        4  \n",
       "973052  0.32760  0.36500  0.34880  0.28350  0.16180        4  \n",
       "\n",
       "[305877 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the columns you want to keep\n",
    "class_3_4_df = class_3_4_df.loc[:, ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A',\n",
    "                              'B9', 'B11', 'B12', 'classes']]\n",
    "class_3_4_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing train and test sets\n",
    "\n",
    "Shuffling dataset first:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B9</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.07330</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.08920</td>\n",
       "      <td>0.1599</td>\n",
       "      <td>0.21980</td>\n",
       "      <td>0.24960</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.29300</td>\n",
       "      <td>0.31260</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.04500</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>0.06720</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.28760</td>\n",
       "      <td>0.33790</td>\n",
       "      <td>0.3388</td>\n",
       "      <td>0.38820</td>\n",
       "      <td>0.34330</td>\n",
       "      <td>0.2761</td>\n",
       "      <td>0.14260</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.05010</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>0.10120</td>\n",
       "      <td>0.1503</td>\n",
       "      <td>0.21470</td>\n",
       "      <td>0.24200</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.29580</td>\n",
       "      <td>0.31110</td>\n",
       "      <td>0.2949</td>\n",
       "      <td>0.17330</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.05465</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.08235</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.21885</td>\n",
       "      <td>0.24865</td>\n",
       "      <td>0.2826</td>\n",
       "      <td>0.29130</td>\n",
       "      <td>0.28510</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.15555</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.02440</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.05660</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.08740</td>\n",
       "      <td>0.10810</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.14960</td>\n",
       "      <td>0.15610</td>\n",
       "      <td>0.3499</td>\n",
       "      <td>0.27660</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305872</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.03140</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.04830</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.37820</td>\n",
       "      <td>0.4132</td>\n",
       "      <td>0.41920</td>\n",
       "      <td>0.45330</td>\n",
       "      <td>0.2147</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305873</th>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.06470</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.09300</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.24270</td>\n",
       "      <td>0.27510</td>\n",
       "      <td>0.2986</td>\n",
       "      <td>0.31230</td>\n",
       "      <td>0.30670</td>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.14920</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305874</th>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.03520</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.05060</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.25670</td>\n",
       "      <td>0.29450</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>0.33220</td>\n",
       "      <td>0.31890</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.10110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305875</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.03840</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.05470</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.28070</td>\n",
       "      <td>0.31925</td>\n",
       "      <td>0.3496</td>\n",
       "      <td>0.35985</td>\n",
       "      <td>0.36015</td>\n",
       "      <td>0.2377</td>\n",
       "      <td>0.12200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305876</th>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.02840</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>0.04990</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.31120</td>\n",
       "      <td>0.37350</td>\n",
       "      <td>0.4120</td>\n",
       "      <td>0.40850</td>\n",
       "      <td>0.40100</td>\n",
       "      <td>0.2259</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305877 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            B1       B2      B3       B4      B5       B6       B7      B8  \\\n",
       "0       0.0495  0.07330  0.0938  0.08920  0.1599  0.21980  0.24960  0.2828   \n",
       "1       0.0353  0.04500  0.0728  0.06720  0.1296  0.28760  0.33790  0.3388   \n",
       "2       0.0340  0.05010  0.0746  0.10120  0.1503  0.21470  0.24200  0.2878   \n",
       "3       0.0494  0.05465  0.0758  0.08235  0.1313  0.21885  0.24865  0.2826   \n",
       "4       0.0207  0.02440  0.0330  0.05660  0.0755  0.08740  0.10810  0.1302   \n",
       "...        ...      ...     ...      ...     ...      ...      ...     ...   \n",
       "305872  0.0164  0.03140  0.0640  0.04830  0.1276  0.30640  0.37820  0.4132   \n",
       "305873  0.0456  0.06470  0.0886  0.09300  0.1601  0.24270  0.27510  0.2986   \n",
       "305874  0.0276  0.03520  0.0597  0.05060  0.1238  0.25670  0.29450  0.3060   \n",
       "305875  0.0323  0.03840  0.0626  0.05470  0.1276  0.28070  0.31925  0.3496   \n",
       "305876  0.0170  0.02840  0.0607  0.04990  0.1289  0.31120  0.37350  0.4120   \n",
       "\n",
       "            B8A       B9     B11      B12  classes  \n",
       "0       0.29300  0.31260  0.2495  0.12940        4  \n",
       "1       0.38820  0.34330  0.2761  0.14260        4  \n",
       "2       0.29580  0.31110  0.2949  0.17330        4  \n",
       "3       0.29130  0.28510  0.2600  0.15555        4  \n",
       "4       0.14960  0.15610  0.3499  0.27660        3  \n",
       "...         ...      ...     ...      ...      ...  \n",
       "305872  0.41920  0.45330  0.2147  0.10220        4  \n",
       "305873  0.31230  0.30670  0.2752  0.14920        4  \n",
       "305874  0.33220  0.31890  0.1979  0.10110        4  \n",
       "305875  0.35985  0.36015  0.2377  0.12200        4  \n",
       "305876  0.40850  0.40100  0.2259  0.11210        4  \n",
       "\n",
       "[305877 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the DataFrame using a random seed, for example, seed=42\n",
    "class_3_4_df = class_3_4_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "class_3_4_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then making splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your features are all columns except 'classes', and 'classes' is the target variable\n",
    "X = class_3_4_df.drop('classes', axis=1)  # Features\n",
    "y = class_3_4_df['classes']  # Target variable\n",
    "\n",
    "# Perform the split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# X_train and y_train will now contain 70% of the data, X_test and y_test will contain 30%\n",
    "# Both splits will have the same proportion of class 0 and 4 as the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 400)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32, log=True)\n",
    "    # Ensuring min_samples_split is an int >= 2\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    # Ensuring min_samples_leaf is a float within (0.0, 0.5], you could also use suggest_int if you want specific integer values\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "\n",
    "    # Initialize the classifier with the current hyperparameters\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth, \n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    # Compute and return the accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-12 17:42:19,150]\u001b[0m A new study created in memory with name: no-name-a881c54c-b5f1-4371-b21f-6791a876ae8c\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:42:47,206]\u001b[0m Trial 0 finished with value: 0.9062050477311364 and parameters: {'n_estimators': 305, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9062050477311364.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:44:04,147]\u001b[0m Trial 1 finished with value: 0.9421777603417463 and parameters: {'n_estimators': 348, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.9421777603417463.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:45:04,822]\u001b[0m Trial 2 finished with value: 0.930223181203958 and parameters: {'n_estimators': 376, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.9421777603417463.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:45:11,795]\u001b[0m Trial 3 finished with value: 0.9062050477311364 and parameters: {'n_estimators': 74, 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.9421777603417463.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:45:51,604]\u001b[0m Trial 4 finished with value: 0.905856327099952 and parameters: {'n_estimators': 397, 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.9421777603417463.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:46:53,159]\u001b[0m Trial 5 finished with value: 0.9808421603243102 and parameters: {'n_estimators': 118, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.9808421603243102.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:47:43,765]\u001b[0m Trial 6 finished with value: 0.9540015692428403 and parameters: {'n_estimators': 157, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.9808421603243102.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:48:52,098]\u001b[0m Trial 7 finished with value: 0.9800793339435945 and parameters: {'n_estimators': 142, 'max_depth': 22, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.9808421603243102.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:49:26,516]\u001b[0m Trial 8 finished with value: 0.930332156401203 and parameters: {'n_estimators': 227, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.9808421603243102.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:49:59,614]\u001b[0m Trial 9 finished with value: 0.9463624079159584 and parameters: {'n_estimators': 135, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.9808421603243102.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:50:32,961]\u001b[0m Trial 10 finished with value: 0.9858877119567586 and parameters: {'n_estimators': 67, 'max_depth': 32, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.9858877119567586.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:50:57,733]\u001b[0m Trial 11 finished with value: 0.9858877119567586 and parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.9858877119567586.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:51:22,719]\u001b[0m Trial 12 finished with value: 0.984765267425134 and parameters: {'n_estimators': 50, 'max_depth': 31, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.9858877119567586.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:52:58,833]\u001b[0m Trial 13 finished with value: 0.9718299115121398 and parameters: {'n_estimators': 226, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.9858877119567586.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:53:43,877]\u001b[0m Trial 14 finished with value: 0.9847761649448585 and parameters: {'n_estimators': 90, 'max_depth': 32, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.9858877119567586.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:54:55,207]\u001b[0m Trial 15 finished with value: 0.9680811647269082 and parameters: {'n_estimators': 176, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9858877119567586.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:55:23,256]\u001b[0m Trial 16 finished with value: 0.9845582145503683 and parameters: {'n_estimators': 56, 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.9858877119567586.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:56:33,921]\u001b[0m Trial 17 finished with value: 0.9641580576260843 and parameters: {'n_estimators': 190, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.9858877119567586.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:58:36,155]\u001b[0m Trial 18 finished with value: 0.9808421603243102 and parameters: {'n_estimators': 263, 'max_depth': 19, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9858877119567586.\u001b[0m\n",
      "\u001b[32m[I 2024-02-12 17:59:24,804]\u001b[0m Trial 19 finished with value: 0.9831960245848045 and parameters: {'n_estimators': 100, 'max_depth': 32, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9858877119567586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'n_estimators': 67, 'max_depth': 32, 'min_samples_split': 8, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)  # Adjust the number of trials as needed\n",
    "\n",
    "print(f\"Best trial: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "Precision: 0.9242534449212805\n",
      "Logistic Regression Accuracy: 0.9220827339697485\n",
      "Recall: 0.9220827339697485\n",
      "F1 Score: 0.9150538025775925\n",
      "Cohen's Kappa: 0.6989004402186524\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "log_reg = LogisticRegression(max_iter=1000) # Increase max_iter if convergence warnings occur\n",
    "\n",
    "# Train the classifier on the training set\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "log_reg_predictions = log_reg.predict(X_test)\n",
    "\n",
    "# Predict on the test set\n",
    "lr_predictions = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate metrics, specifying pos_label for binary classification\n",
    "lr_precision = precision_score(y_test, lr_predictions, average='weighted')\n",
    "log_reg_accuracy = accuracy_score(y_test, log_reg_predictions)\n",
    "lr_recall = recall_score(y_test, lr_predictions, average='weighted')\n",
    "lr_f1 = f1_score(y_test, lr_predictions, average='weighted')\n",
    "lr_kappa = cohen_kappa_score(y_test, lr_predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(f\"Precision: {lr_precision}\")\n",
    "print(f'Logistic Regression Accuracy: {log_reg_accuracy}')\n",
    "print(f\"Recall: {lr_recall}\")\n",
    "print(f\"F1 Score: {lr_f1}\")\n",
    "print(f\"Cohen's Kappa: {lr_kappa}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then RF model based on optimised hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Performance:\n",
      "Precision: 0.9859596602559151\n",
      "Recall: 0.9858877119567586\n",
      "F1 Score: 0.985716586950859\n",
      "Cohen's Kappa: 0.9519447343420772\n",
      "Optimized RandomForest Accuracy: 0.9858877119567586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Best trial: {'n_estimators': 67, 'max_depth': 32, 'min_samples_split': 8, 'min_samples_leaf': 1}\n",
    "\n",
    "# Assuming you have your optimized hyperparameters, for example:\n",
    "optimized_hyperparameters = {\n",
    "    'n_estimators': 67,\n",
    "    'max_depth': 32,\n",
    "    'min_samples_split': 8,\n",
    "    'min_samples_leaf': 1, \n",
    "    # Include other hyperparameters as necessary\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with optimized hyperparameters\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=optimized_hyperparameters['n_estimators'],\n",
    "    max_depth=optimized_hyperparameters['max_depth'],\n",
    "    min_samples_split=optimized_hyperparameters['min_samples_split'],\n",
    "    min_samples_leaf=optimized_hyperparameters['min_samples_leaf'],\n",
    "    random_state=42  # Ensuring reproducibility\n",
    ")\n",
    "\n",
    "# Train the classifier on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Compute and display the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "rf_precision = precision_score(y_test, predictions, average='weighted')\n",
    "rf_recall = recall_score(y_test, predictions, average='weighted')\n",
    "rf_f1 = f1_score(y_test, predictions, average='weighted')\n",
    "rf_kappa = cohen_kappa_score(y_test, predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(\"RandomForest Performance:\")\n",
    "print(f\"Precision: {rf_precision}\")\n",
    "print(f\"Recall: {rf_recall}\")\n",
    "print(f\"F1 Score: {rf_f1}\")\n",
    "print(f\"Cohen's Kappa: {rf_kappa}\")\n",
    "print(f'Optimized RandomForest Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming predictions, y_test are already defined\n",
    "\n",
    "# Compute the normalized confusion matrix\n",
    "cm_normalized = confusion_matrix(y_test, predictions, labels=[3, 4], normalize='true')\n",
    "\n",
    "# Visualize the normalized confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt=\".2%\", cmap=\"Greens\", xticklabels=[3, 4], yticklabels=[3, 4])\n",
    "plt.title('Normalised Confusion Matrix Round 5 No. 9')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Save the figure with a white background\n",
    "plt.savefig('round5_no9_matrix.png', bbox_inches='tight', pad_inches=0, facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAI4CAYAAAB3OR9vAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA5EUlEQVR4nO3dfZhdZXno/+9t5CVUqZakLUoCvkFiox17ojU0lATS8lLy0/6gxKmh0MaEwim98quec4yBtscQqC14UvUXJGnaFKhpUqitScGXpIkaE9sCDoqGIPgW1CqJUKWJFuJ9/tgrujLMJLOz92TNWvP9XNe+svd6eda9nqy9555n7mftyEwkSZIktTyn6gAkSZKkkcQEWZIkSSoxQZYkSZJKTJAlSZKkEhNkSZIkqcQEWZIkSSoxQZbUNRHx/oi4ruo4NDJFxFciYlbVcXRbRBwXEV+IiJOrjuVIFefwUESMrzoWaSQwQZaOsiJJ2BcRT0XEtyJidUQ8bwTEtToirm9j+ysiYmt5WWb+bmYuGYbY/jgi7uh2u0dioPMeyYp49xfX23cj4oGIuKjquPor/o+fLuI88HjpINvOiIiMiOX9lm+NiCu6EMuLI+IfI+I7EfFYRPzuYXZZAHwiM79Z7N/We+kQcZxWnOdzO21rgLa3RMRbDrzOzB8Afwm8vdvHkurIBFmqxuzMfB7wC8BU4Np2do4W379H2XAkKkfJ9uJ6ewGwHPjbiHhBpRENbG1mPq/0+NIhtv1P4LKIOG0Y4rgD+DLwM8CvATdExMxDbP+7wO3DEMfR9gHg8og4rupApKr5A1aqUGZ+HbgHmAIQEa+PiG0R8WQx0jfjwLbFiM/SiPgUsBd4aTG6dHVEfDEivhcRSyLiZUUb342IdRFxbLH/s0Y+i/1fHhELgDcD/7MYuVtfrH97RDxatP2FiPj1Yvlk4P3AtGL7J4vlB42cRcT8iHikGIn7UES8qN+xf7eI/cmI+P8jIobSb22e94xiFPAdEbG7GMF/c6mtn4yI2yLi8Yj4akRce+CXj6LPPhUR/yci9gBrBznvX4uIzxTH3hURf1xq/8Ao4OUR8bUihsWl9WOK2A70830RMaFYNykiPlb0386IuLS034XF/8n3IuLrEfG2w/VbZv6QViL3E8ArhnD+B43c9x/RLK7JJUUffS8iPhoR40rbX1a0uad8zl3yJLAa+KOBVkbEc4pz+WpEfLs4x588XKPR+mvODGBpZj6dmQ8AdwK/M8j2E4GXAv9SvB7svfSiiLir6OcvR8Tvl9p4XUTcW1w/34qIdxerPnHgXIu2pg1w/MH2HfTzJCKWAmcB7yvafR9AZj4GPAG8/nD9JDVeZvrw4eMoPoCvALOK5xOAzwNLgBcDe4ALaf3y+ivF6/HFtluArwE/BzwXOAZI4B+BE4vlPwA20fqB/ZPAF4DLi/2vALb2iyWBlxfPVwPX91v/G8CLinjm0Bq1O/kQ7f2oDeAcYDetUfLjgPfS+jN0+dgbaI1qTgQeB84fpM/+GLij375DPe8ZwDPAu4s4zi7O44xi/W1FW88HTgMeBuaVzvEZ4Jqiz8cOct4zgFcV/fRq4FvAG4t1pxXxriz2//ki3snF+v8BfA44A4hi/Um0kthdwG8Xx35N0Z+vLPb7JnBW8fyFwC8M0nc/ihcYA/x34L+Anx7C+ffv9wPn8tzSNfkocHpxbluAPynWvRJ4Cvjlot/fXfTlrEP8H/8H8B1a74mrDvEemgE8Bvws8N3S/+VW4Iri+e8Aj9C6Jp4H/D1w+xDen88vzvGnS8tWAp8ZZPtfAz4/2PugeP0c4D7gD4Fji5i+BJxXrN8OXFY8fx7w+oH6e5DjD7bvUD5P3jJAex8Cfr+qz0cfPkbKwxFkqRr/UIw+bgU+DtwAzAXuzsy7M/OHmfkx4F5aP+AOWJ2Zn8/MZzLz6WLZn2bmdzPz88CDwEcz80uZ+R+0Rqdfc6RBZubfZeY3injWAl8EXjfE3d8M/GVm3p+t+sZFtEZeTytt8yeZ+WRmfg3YDPS0EV67531dZv4gMz8O/BNwaUSMAd4ELMrM72XmV4CbgctK+30jM99b9Pm+gQLJzC2Z+bminz4LrKGViJf978zcl60RyQdoJcIAbwGuzcyd2fJAZu4BLgK+kpl/VRz7M8BdtH5pAXgaeGVEnJiZT2Tm/Yfoq9cX19v3gZuAuZn57SGe/+H8VWY+XPTNOn78f3gJsCEzP1H8/18H/PAQ7awDJgPjgfnAH0ZE76EOnJn/TmtE/50DrH4z8O7imniK1vX3pjhMmUxmfg/4FHBdRBwfEb8AXAycMMguLwC+d6g2gdfSSkzfmZn/la3SkZW0+h5a/5cvj4hxmflUZn76MO2VDbbvUD5PBvK94pykUc0EWarGGzPzBZl5amZeXSQXpwK/Ufw59MkioZkOlGfG7xqgrW+Vnu8b4PURTwCMiN+KiL5SPFOAcYfZ7YAXAV898KJIUvbQGtk64N9Lz/e2GWs75/1EZv5n6fVXi/jG0RqJ/2q/deUYB+rzg0TEL0bE5uLP5/9Bqya1fz8Ndq4TaI3C9ncq8Iv9roc30xo1hVbSdiHw1Yj4+EB/fi/5dGa+gNZI84do/Xkdhnb+hzPYeb2IUt8V/b9nsEYy8wvFL2P7M3Mb8Oe0kuzDeRdwXkT8fL/lB11/xfPn0qorPpw3Ay8p4r+FVk3yY4Ns+wStUedDORV4Ub//y3eUYplHaxT+oYj4t2hvEuVg+w7l82Qgz6dVviKNanWdcCI10S5afwKef4htsoP2/5PSKFhE/Gy/9Qe1HRGn0hrlOpfWJK/9EdFHqwxgKLF8g9YP6QPt/QSt0oGvH0nwHXphRPxEKUmeSGvUeTetEbhTaZVlHFhXjrH/eQ503h8A3gdckJnfj4hlDP0XiV3Ay4p4+i//eGb+ykA7Zea/AW+IiGOA36M1AjvhUAfKzKci4irgSxHxl8BnOfT5H3TN8OPkfCi+SWtEGICIOIHW//9QJT++1gbfKHNP0d/9755y0PVH67ye4eBfpAZr86u0RvABiIgPAP86yOafBV4SEc/NzGdKsZftAr6cma8Y5HhfBHqL2u//F7gzIk4aoJ129j3c58lgbU+m9VcEaVRzBFkaOe4AZkfEedGauHV8tCaYndKl9h8Afi4ieiLieFo1n2XfolUbecBP0Poh+jhARPw2xWTC0vanRDEZbgBrgN8ujnccrTKSfyn+jF+F/x0Rx0bEWbSSn7/LzP20EsulEfH84peCP6D1fzGYgc77+cB3iuT4dcBvthHXXwBLIuIV0fLqIsHZAJwerYluxxSP10bE5OI83hwRP1mU2nyXQ5cv/Ehmfqc45h8O4fz7gF+OiInRmuC2qI3zuhO4KCKmF331Tg7xMyci3hARLyz64HXA79OqjR6KdwNnUkrIaV1//19EvCRaE+9uoHWXjGcGaqBfLJOL/jg2IuYCv1oc41myNbHtEQ4uPer/XvpX4HsR8b8iYmzx/p4SEa8tjjc3IsZnaxLlk8U+P6T13vthv7b6xzrYvof7POkfIxHxYuCngHZKPKRGMkGWRojM3AW8gdafXh+nNQL0P+jS+zQzH6aVpGykVUvc/16+q2jVtD4ZEf+QmV+gNZK0ndYP01fRqs084J9pTab694jYPcDxNtKqO72L1mjiy/hxzeXR9u+0/hT+DeBvgN/NzIeKddfQGin9Eq0++QCt+8EOZqDzvhp4Z0R8j9ZErHVtxPbuYvuP0kp0VwFji1rYX6XVZ98ozuFdtCa8QatO+CsR8V1aJR1vZuiWARdGxKs5xPkXdatraY2S3kcraR+Sojb8vxftfZNW/w9WpgCt83yEVg3sbcC7MvOvh3is7wJ/Siu5O+Avad2x4xO0btn2fVrnSkScFRFPHaLJ82j1xxO0+vb8zHz8ENvfysF12/3fS/tp/VLWU8Sym9YvKQfuqnE+8Pkipj8H3lTUq+8FlgKfKtoa6O4Sg+17uM+TPwcuiYgnIuI9xbLfBP66qBmXRrXI7OQvtpI0skXr1lZ3ZGa3RuKlgxR/IfkMcG4WXxZSN8U5PAD8cmZ+u+p4pKpZgyxJUgeKEddXVh1HJ4pzmFR1HNJIYYmFJEmSVGKJhSRJklTiCLIkSZJUMmJqkMeNG5ennXZa19vduXMnAGeccUbX25YkSVJ93Xfffbszc3z/5SMmQT7ttNO49957u97ujBkzANiyZUvX25YkSVJ9RcRXB1puiYUkSZJUYoIsSZIklZggS5IkSSUjpgZ5uCxbtqzqECRJklQjjU+Qe3p6qg5BkiRJNdL4EouNGzeycePGqsOQJElSTTR+BPn6668HYNasWRVHIkmSpDpo/AiyJEmS1A4TZEmSJA27mB/E/ICHWo+YH1WHNCgTZEmSJKnEBFmSJEkqafwkvVtvvbXqECRJklQjjU+QzzjjjKpDkCRJUo00vsRi/fr1rF+/vuowJEmSVBONH0G++eabAZg9e3bFkUiSJKnswJ0scmVWHMnBGj+CLEmSJLXDBFmSJEkq6ShBjoj9EdEXEQ9ExP0RcWZp3Ycj4smI2NB5mJIkSaqDNWvWMGXKFMaMGcOUKVNYs2ZN1SG1rdMa5H2Z2QMQEecBNwJnF+v+DDgBuLLDY0iSJKkG1qxZw+LFi1m1ahXTp09n69atzJs3r+qw2tbNSXonAk8ceJGZmyJiRhfbPyK333571SFIkiSNCkuXLmXVqlXMnDkTgJkzZ7Jq1SquueYamFZxcG3oNEEeGxF9wPHAycA57ewcEQuABQATJ07sMJSBTZgwYVjalSRJ0sF27NjB9OnTD1o2ffp0duzYUasEudNJevsysyczJwHnA7dFRAx158xckZlTM3Pq+PHjOwxlYGvXrmXt2rXD0rYkSZJ+bPLkyWzduvWgZVu3bmXy5MkVRXRkunYXi8zcDowDhifTPUK33HILt9xyS9VhSJIkNd7ixYuZN28emzdv5umnn2bz5s3MmzePxYsXVx1aW7pWgxwRk4AxwJ5utSlJkqT66O3tBeCaa65hx44dTJ48maVLl9Lb28tv/vNvVhzd0HWrBhkggMszcz9ARHwSmAQ8LyIeA+Zl5kc6PJ4kSZJGsN7e3h8lynXVUYKcmWMOse6sTtqWJEmSquA36UmSJEkl3bwP8oh05513Vh2CJEmSBpArs+oQBtT4BHncuHFVhyBJkqQaaXyJxerVq1m9enXVYUiSJKkmTJAlSZKkksYnyJIkSVI7Gl+DLEmSpOr1n5CXKysKZAgcQZYkSZJKTJAlSZKkksaXWNx9991VhyBJkqQaaXyCfMIJJ1QdgiRJkmqk8SUWy5cvZ/ny5VWHIUmSpJpofIK8bt061q1bV3UYkiRJqonGJ8iSJElSO0yQJUmSpBITZEmSJKnEBFmSJEkqafxt3rZs2VJ1CJIkSaoRR5AlSZKkksYnyDfddBM33XRT1WFIkiSpJhqfIG/YsIENGzZUHYYkSZJqovEJsiRJktQOE2RJkiSpxARZkiRJKmn8bd7Gjh1bdQiSJEmqkcYnyPfcc0/VIUiSJKlGGp8gS5I68FAAEDe3XubKrDAYSTo6Gl+DvGTJEpYsWVJ1GJIkSaqJxifImzZtYtOmTVWHIUmSpJpofIIsSZIktcMEWZIkSSoxQZYk/UjMD2J+HPF6SWqCxt/F4qSTTqo6BEmSJNVI4xPku+66q+oQJEmSVCNDKrGIiP0R0RcRD0TE/RFxZmndhyPiyYjY0G+fv4mInRHxYET8ZUQc0+3gJUmSpG4bag3yvszsycyfBxYBN5bW/Rlw2QD7/A0wCXgVMBZ4SyeBHqlFixaxaNGiKg4tSY21Zs0apkyZwpgxY5gyZQpr1qypOiRJ6pojKbE4EXjiwIvM3BQRM/pvlJl3H3geEf8KnHIEx+rY9u3bqzisJDXXo7B402JWrVrF9OnT2bp1K/PmzQOgt7e34uAkqXNDHUEeW5RYPAT8BTDkr6YrSisuAz58BPFJkipwyLtV9MGqVauYOXMmxxxzDDNnzmTVqlUsXbr0qMYoScOl3RKLScD5wG0RMdT7/CwHPpGZn+y/IiIWRMS9EXHv448/PsTmJEmVehKmT59+0KLp06ezY8eOauKRpC5r+z7ImbkdGAeMP9y2EfFHxXZ/MEhbKzJzamZOHT/+sM1Jko6SXJnkyhx45Qtg69atBy3aunUrkydPHv7AJOkoaDtBjohJwBhgz2G2ewtwHtCbmT88svA6d8opp3DKKZWUP0tSM/XAvHnz2Lx5M08//TSbN29m3rx5LF68uOrIJKkrhjpJb2xE9BXPA7g8M/cDRMQnad2t4nkR8RgwLzM/Arwf+CqwvajG+PvMfGc3gx+KO+6442gfUpKa7WWwdP5SrrnmGnbs2MHkyZNZunSpE/QkNcaQEuTMHHOIdWcNsrzxX0IiSaNVb2+vCbGkxmq7xKJuFi5cyMKFC6sOQ5IkSTXR+FHevr6+qkOQpNoYdGLeENdLUhM0fgRZkiRJaocJsiRJklRigixJkiSVNL4G+fTTT686BEmSJNVIZI6MCRdTp07Ne++9t+owJEmSNEpExH2ZObX/ckssJEmSpJLGJ8gLFixgwYIFVYchSZKkmmh8DfLDDz9cdQiSJEmqkcaPIEuSJEntMEGWJEmSSkyQJUmSpJLG1yD39PRUHYIkSZJqpPEJ8rJly6oOQZIkSTViiYUkSZJU0vgEee7cucydO7fqMCRJklQTjS+xeOyxx6oOQZIkSTXS+BFkSZIkqR0myJIkSVKJCbIkSZJU0vga5GnTplUdgiRJkmqk8QnyjTfeWHUIkiRJqhFLLCRJkqSSxifIF198MRdffHHVYUiSJKkmGl9isWfPnqpDkCRJUo00fgRZ0sgQ84OYH/BQ6xHzo+qQJEkakAmyJEmSVGKCLEmSJJU0vgb53HPPrToESZIk1UjjE+Trrruu6hAkSZJUI5ZYSJIkSSWNT5AvuOACLrjggqrDkDQA72QhSRqJGl9isW/fvqpDkCRJUo00fgRZkiRJakdHCXJE7I+Ivoh4ICLuj4gzS+veFREPFo85nYcqSZIkDb9OSyz2ZWYPQEScB9wInB0Rvwb8AtADHAdsiYh7MvO7HR5PkiRJGlbdrEE+EXiieP5K4BOZ+QzwTER8FjgfWNfF4w3JRRdddLQPKUmSpBrrNEEeGxF9wPHAycA5xfIHgD+KiJuBE4CZwBf67xwRC4AFABMnTuwwlIG97W1vG5Z2JUmS1EzdLLGYBtwWEVMy86MR8VpgG/A4sB3Y33/nzFwBrACYOnVqdhiLJEmS1LGu3cUiM7cD44DxxeulmdmTmb8CBPBwt47VjhkzZjBjxowqDi1JkqQa6lqCHBGTgDHAnogYExEnFctfDbwa+Gi3jiVJkiQNl27VIENrlPjyzNwfEccDn4wIgO8Cc4sJe5IkSdKI1lGCnJljBln+fVp3spAkSZJqxW/Sk1SZXOncXEnSyNPN+yCPSJdeemnVIUiSJKlGGp8gX3311VWHIEmSpBppfInF3r172bt3b9VhSJIkqSYaP4J84YUXArBly5ZqA5EkSVItNH4EWZIkSWpH40eQJY0M/e9YkSsrCkSSpMNwBFmSJEkqMUGWJEmSShpfYnHFFVdUHYIkSZJqxARZkiRJKml8icXu3bvZvXt31WFIkiSpJho/gnzJJZcA3gdZkiRJQ9P4EWRJkiSpHSbIkiRJUokJsiRJklRigixJkiSVNH6S3lVXXVV1CJIkSaqRxifIc+bMqToESZIk1UjjSyx27drFrl27qg5DkiRJNdH4EeTLLrsM8D7IkiRJGprGjyBLkiRJ7TBBliRJkkpMkCVJkqQSE2RJkiSppPGT9N761rdWHYIkSZJqpPEJ8uzZs6sO4cg9FADEzZArs+JgJEmSRofGl1js3LmTnTt3Vh2GJEmSaqLxI8hXXnkl4H2QJUmSNDSNH0GWJEmS2mGCLEmSJJWYII9QMT+e9br/MkmSJHWfCbIkSZJU0vhJetdee23VIUiSJKlGhjSCHBH7I6IvIh6IiPsj4szSug9HxJMRsaHfPr8XEY9EREbEuG4HPlSzZs1i1qxZVR1ekiRJNTPUEot9mdmTmT8PLAJuLK37M+CyAfb5FDAL+GpnIXamr6+Pvr6+KkOQJElSjRxJicWJwBMHXmTmpoiY0X+jzPwMQES1E8sWLlwIeB9kSZIkDc1QE+SxEdEHHA+cDJzTjYNHxAJgAcDEiRO70aQkSZLUkXZLLCYB5wO3RReGhjNzRWZOzcyp48eP77Q5SZIkqWNt3+YtM7cD4wAzWkmSJDVO2wlyREwCxgB7uh+OJEmSVK12a5ABArg8M/cDRMQngUnA8yLiMWBeZn4kIn4f+J/AzwKfjYi7M/Mt3Q3/8G644YajfUhJkiTV2JAS5Mwcc4h1Zw2y/D3Ae44wrq4588wzD7+RJEmSVGj8V01v27aNbdu2VR2GJEmSaqLxXzX9jne8A6jffZBzZcJDcfBrSZIkDbvGjyBLkiRJ7TBBliRJkkpMkCVJkqQSE2RJkiSppPGT9JYtW1Z1CEduUmtiXq6sOA5JkqRRpPEJck9PT9UhSJIkqUYaX2KxceNGNm7cWHUYkiRJqonGjyBff/31AMyaNaviSCRJklQHjR9BliRJktphgixJkiSVmCBLkiRJJSbIkiRJUknjJ+ndeuutVYcgSZKkGml8gnzGGWdUHYIkSZJqpPElFuvXr2f9+vVVhyFJkqSaaPwI8s033wzA7NmzK45EkiRJddD4EWRJkiSpHSbIkiRJUokJsiRJklRigixJkiSVNH6S3u233151CJIkSaqRxifIEyZMqDoESZIk1UjjSyzWrl3L2rVrqw5DkiRJNdH4EeRbbrkFgDlz5lQciSRJkuqg8SPII1HMD3ioeEiSJGlEMUGWJEmSSkyQJUmSpBITZEmSJKmk8ZP07rzzzqpDkCRJUo00PkEeN25c1SEcJOY7MU+SJGkka3yJxerVq1m9enXVYUiSJKkmTJAlSZKkksYnyJIkSVI7OkqQI2J/RPRFxAMRcX9EnDnAur6I+FDnoTbTmDFjmDJlCmvWrKk6FEmSJNH5JL19mdkDEBHnATcCZ/dfp8F9//vfZ+vWrcybNw+A3t7eiiOSJEka3bpZYnEi8EQX2xsVjjnmGGbOnMmqVatYunRp1eFIkiSNep2OII+NiD7geOBk4JzSuuMj4l7gGeBPMvMf+u8cEQuABQATJ07sMJSB3X333cPSbrdNnz6dHTt2VB2GJEnSqNfNEotpwG0RMSUzEzg1M78eES8F/jkiPpeZj5Z3zswVwAqAqVOnZoexDOiEE04Yjma7buvWrUyePLnqMCRJkka9rpVYZOZ2YBwwvnj99eLfLwFbgNd061jtWL58OcuXL6/i0EPy9NNPs3nzZubNm8fixYurDkeSJGnU69o36UXEJGAMsCciXgjszcwfRMQ44JeAP+3Wsdqxbt06AK6++uoqDn9Yxx9/PJMnT2bp0qVO0JMkSRoBulWDDBDA5Zm5PyImA7dGxA9pjVL/SWZ+ocNjNdL+/furDkGSJEklHSXImTlmkOXbgFd10rYkSZJUBb9J7yjLlcMyF1GSJEldYoIsSZIklXRtkt5ItWXLlqpDkCRJUo04gixJkiSVND5Bvummm7jpppuqDkOSJEk10fgEecOGDWzYsKHqMCRJklQTja9BHom8k4UkSdLI1fgRZEmSJKkdJsiSJElSSeNLLMaOHVt1CJIkSaqRxifI99xzT9UhSJIkqUYssZAkSZJKGp8gL1myhCVLllQdhiRJkmqi8Qnypk2b2LRpU9VhSJIkqSYanyBLkiRJ7TBBliRJkkpMkCVJkqSSxt/m7aSTTqo6BEmSJNVI4xPku+66q+oQJEmSVCOWWEiSJEkljU+QFy1axKJFi6oOQ5IkSTXR+BKL7du3Vx2CJEmSaqTxI8iSJElSO0yQJUmSpBITZEmSJKmk8TXIp5xyStUhSJIkqUYanyDfcccdR+9gD0Xr30l59I4pSZKkrrLEQpIkSSppfIK8cOFCFi5cWHUYkiRJqonGl1j09fVVHYIkSZJqpPEjyJIkSVI7TJC7JObHgM8lSZJULybIkiRJUknja5BPP/30qkOQJElSjXSUIEfEfuBzQAD7gd/LzG2l9ScCXwD+ITN/r5NjHakVK1ZUcVhJkiTVVKcjyPsyswcgIs4DbgTOLq1fAnyiw2NIkiRJR003a5BPBJ448CIi/hvwM8BHu3iMti1YsIAFCxZUGYIkSZJqpNMR5LER0QccD5wMnAMQEc8BbgbmArMG2zkiFgALACZOnNhhKAN7+OGHh6VdSZIkNVOnI8j7MrMnMycB5wO3RUQAVwN3Z+Zjh9o5M1dk5tTMnDp+/PgOQ5EkSZI617W7WGTm9ogYB4wHpgFnRcTVwPOAYyPiqcx8e7eOJ0mSJA2HriXIETEJGAPsycw3l5ZfAUw1OZYkSVIddKsGGVq3ers8M/d32GZX9fT0VB2CJEmSaqSjBDkzxwxhm9XA6k6O04lly5ZVdWhJkiTVkF81LUmSJJU0PkGeO3cuc+fOHfbj5Moc8LkkSZLqpWuT9Eaqxx475J3mJEmSpIM0fgRZkiRJaocJsiRJklRigixJkiSVNL4Gedq0aUfvYJOcnCdJklR3jU+Qb7zxxqpDkCRJUo1YYiFJkiSVND5Bvvjii7n44ourDkOSJEk10fgSiz179lQdgiRJkmqk8SPIkiRJUjtMkCVJkqQSE2RJkiSppPE1yOeee27VIUiSJKlGGp8gX3fddVWHIEmSpBqxxEKSJEkqaXyCfMEFF3DBBRdUHYYkSZJqovElFvv27as6BEmSJNVI40eQJUmSpHaYIEuSJEklJsiSJElSSeNrkC+66KKqQ5AkSVKNND5Bftvb3lZ1CJIkSaoRSywkSZKkksYnyDNmzGDGjBlVhyFJkqSaaHyCfLTE/ICHiockSZJqywRZkiRJKjFBliRJkkpMkCVJkqSSxt/m7dJLL606BEmSJNVI4xPkq6++uuoQJEmSVCONL7HYu3cve/furToMSZIk1UTjR5AvvPBCALZs2VJtIJIkSaqFxo8gS5IkSe3oKEGOiP0R0RcRD0TE/RFxZmndxIj4aETsiIgvRMRpHUcrSZIkDbNOSyz2ZWYPQEScB9wInF2suw1Ympkfi4jnAT/s8FiSJEnSsOtmDfKJwBMAEfFK4LmZ+TGAzHyqi8eRJEmShk2nCfLYiOgDjgdOBs4plp8OPBkRfw+8BNgIvD0z95d3jogFwAKAiRMndhjKwK644ophaVeSJEnN1M0Si2nAbRExpWj3LOA1wNeAtcAVwKryzpm5AlgBMHXq1OwwlgGZIEuSJKkdXbuLRWZuB8YB44HHgL7M/FJmPgP8A/AL3TpWO3bv3s3u3burOLQkSZJqqGs1yBExCRgD7CkeL4iI8Zn5OK3Si3u7dax2XHLJJYD3QZYkSdLQdKsGGSCAyw/UGUfE24BNERHAfcDKDo8lSZIkDbuOEuTMHHOIdR8DXt1J+5IkSdLR5jfpSZIkSSUmyJIkSVJJN78oZES66qqrqg5BkiRJNdL4BHnOnDlVhyBJkqQaaXyJxa5du9i1a1fVYUiSJKkmGj+CfNlllwHeB1mSJElD0/gE+WjJlcPyTdmSJEk6yhpfYiFJkiS1wwRZkiRJKjFBliRJkkoaX4P81re+teoQJEmSVCONT5Bnz55ddQiSJEmqkcaXWOzcuZOdO3dWHYYkSZJqovEjyFdeeSXgfZAlSZI0NI0fQZYkSZLaYYIsSZIklZggS5IkSSUmyJIkSVJJ4yfpXXvttVWHIEmSpBppfII8a9asqkOQJElSjTS+xKKvr4++vr6qw5AkSVJNNH4EeeHChYD3QZYkSdLQNH4EWZIkSWqHCbIkSZJUYoIsSZIklZggdyDmBzxUPCRJktQIjZ+kd8MNN1QdgiRJkmqk8QnymWeeWXUIkiRJqpHGl1hs27aNbdu2VR2GJEmSaqLxI8jveMc7AO+DLEmSpKFp/AiyJEmS1A4T5C6J+d7JQpIkqQlMkCVJkqQSE2RJkiSppKMEOSL2R0RfRDwQEfdHxJnF8pnF8gOP70fEG7sScZuWLVvGsmXLutrmmjVrmDJlSlfblCRJ0sjQ6V0s9mVmD0BEnAfcCJydmZuBA8t/CngE+GiHxzoiPT09XW1vzZo1LF68mFWrVnHOB8758YpHu3oYSZIkVaSbJRYnAk8MsPwS4J7M3NvFYw3Zxo0b2bhxY9faW7p0KatWrWLmzJkHr+jr2iEkSZJUoU5HkMdGRB9wPHAycM4A27wJePdAO0fEAmABwMSJEzsMZWDXX389ALNmzepKezt27GD69OnPXvFkV5qXJElSxTodQd6XmT2ZOQk4H7gtIn50v7OIOBl4FfCRgXbOzBWZOTUzp44fP77DUI6OyZMns3Xr1meveMFRD0WSJEnDoGslFpm5HRgHlDPdS4EPZubT3TpO1RYvXsy8efPYvHnzwSt6KglHkiRJXda1r5qOiEnAGGBPaXEvsKhbxxgJent7AbjmmmtgWmnFy6qJR5IkSd3V6Qjy2AO3cgPWApdn5n6AiDgNmAB8vMNjjDi9vb08+OCDVYchSZKkYdDRCHJmjjnEuq8AL+6k/W649dZbqw5BkiRJNdK1EouR6owzzqg6BEmSJNVI479qev369axfv37Yj5Mrc9iPIUmSpOHX+BHkm2++GYDZs2dXHIkkSZLqoPEjyJIkSVI7TJAlSZKkEhNkSZIkqaTxNcjDyYl5kiRJzdP4BPn222+vOgRJkiTVSOMT5AkTJlQdgiRJkmqk8TXIa9euZe3atVWHIUmSpJpo/AjyLbfcAsCcOXMqjkSSJEl10PgRZEmSJKkdJsiSJElSiQmyJEmSVGKCLEmSJJU0fpLenXfeWXUIkiRJqpHGJ8jjxo2rOgRJkiTVSONLLFavXs3q1aurDkOSJEk1YYIsSZIklTQ+QZYkSZLaYYIsSZIklZggS5IkSSUmyJIkSVJJ42/zdvfdd1cdgiRJkmqk8QnyCSecUHUIkiRJqpHGl1gsX76c5cuXVx2GJEmSaqLxCfK6detYt25d19qL+QEPtR4xP7rWriRJkkaGxifIkiRJUjtMkCVJkqQSE2RJkiSpxARZkiRJKmn8bd62bNnStbYGmpQX84NcmV07hiRJkqrlCLIkSZJU0vgE+aabbuKmm26qOgxJkiTVROMT5A0bNrBhw4aqw5AkSVJNdJQgR8T+iOiLiAci4v6IOLNY3hMR2yPi8xHx2YiY051wJUmSpOHV6SS9fZnZAxAR5wE3AmcDe4HfyswvRsSLgPsi4iOZ+WSHx5MkSZKGVTfvYnEi8ARAZj58YGFmfiMivg2MB57s4vEkSZKkrus0QR4bEX3A8cDJwDn9N4iI1wHHAo8OsG4BsABg4sSJHYYySIBjxw5Lu5IkSWqmbpZYTANui4gpmZnFspOB24HLM/OH/XfOzBXACoCpU6cOy82E77nnnuFoVpIkSQ3VtbtYZOZ2YBytUgoi4kTgn4DFmfnpbh1HkiRJGk5dS5AjYhIwBtgTEccCHwRuy8w7u3WMI7FkyRKWLFlSZQiSJEmqkU4T5LHFbd76gLW0Sin2A5cCvwxccWB9RPR0eKwjsmnTJjZt2lTFoSVJklRDHdUgZ+aYQZbfAdzRSduSJElSFRr/TXrdlCufPY9woGWSJEmqLxNkSZIkqaSbXxQyIp100klVhyBJkqQaaXyCfNddd1UdgiRJkmrEEgtJkiSppPEJ8qJFi1i0aFHVYUiSJKkmGl9isX379q62V75rRa7satOSJEkaARo/gixJkiS1wwRZkiRJKjFBliRJkkoaX4N8yimnVB2CJEmSaqTxCfIdd9xRdQiSJEmqEUssJEmSpJLGJ8gLFy5k4cKFVYchSZKkmmh8iUVfX1/VIUiSJKlGGj+CLEmSJLXDBFmSJEkqMUGWJEmSShpfg3z66adXHYIkSZJqpPEJ8ooVK6oOQZIkSTViiYUkSZJU0vgEecGCBSxYsKDqMCRJklQTjS+xePjhh6sOQZIkSTXS+BFkSZIkqR0myJIkSVKJCfJQPRSthyRJkhqt8TXIPT09VYcgSZKkGml8grxs2bKqQ5AkSVKNWGIhSZIklTQ+QZ47dy5z586tOgxJkiTVRONLLB577LGqQ5AkSVKNNH4EuRtivnevkCRJGi1MkCVJkqQSE2RJkiSp5LAJckTsj4i+iHggIu6PiDNL6/40Ij4fETsi4j0REaV1PRGREXH+cAU/FNOmTWPatGlVhiBJkqQaGcokvX2Z2QMQEecBNwJnF4nyLwGvLrbbCpwNbCle9xbLeoEPdy/k9tx4441VHVqSJEk11O5dLE4EniieJ3A8cCwQwDHAtwCKkeTfAH4F+GREHJ+Z3+9KxJIkSdIwGkqCPDYi+mglwycD5wBk5vaI2Ax8k1aC/L7M3FHscybw5cx8NCK2AL8G3NW/4YhYACwAmDhxYmdnMoiLL74YgLvuetbhJUmSpGcZyiS9fZnZk5mTgPOB26Ll5cBk4BTgxcA5EXFWsU8v8LfF878tXj9LZq7IzKmZOXX8+PEdnchg9uzZw549e4albUmSJDVPWyUWxajxOGA88OvApzPzKYCIuAeYFhHbgIuBN0TEYlqjyydFxPMz83vdDV+SJEnqrrZu8xYRk4AxwB7ga7Qm6z03Io6hNUFvB3Au8NnMnJCZp2XmqbTKK369u6FLkiRJ3ddODTK0RoMvz8z9EXEnrXrkz9GasPfhzFwfEX8FfLBfG3cBVwG3dSdsSZIkaXgcNkHOzDGDLN8PXDnA8t8eYNmHgA8dSYCdOvfcc6s4rCRJkmqq3du81c51111XdQiSJEmqEb9qeghyZVYdgiRJko6SxifIF1xwARdccEHVYUiSJKkmGl9isW/fvqpDkCRJUo00fgRZkiRJaocJsiRJklTS+BKLrpnkRD1JkqTRoPEJ8kUXXVR1CJIkSaqRxifIb3vb26oOQZIkSTViDbIkSZJU0vgEecaMGcyYMaPqMCRJklQTjU+QJUmSpHaYIEuSJEklJsiSJElSiQmyJEmSVNL427xdeumlVYcgSZKkGml8gnz11VdXHYIkSZJqpPElFnv37mXv3r1VhyFJkqSaaPwI8oUXXgjAli1bqg1EkiRJtdD4EWRJkiSpHSbIkiRJUokJsiRJklRigixJkiSVNH6S3hVXXFF1CJIkSaoRE2RJkiSppPElFrt372b37t1VhyFJkqSaaPwI8iWXXAK0eR/kh6L176TsfkCSJEka0Ro/gixJkiS1wwRZkiRJKjFBliRJkkpMkCVJkqSSxk/Su+qqq9raPuYH+dZhCkaSJEkjXuMT5Dlz5lQdgiRJkmqk8SUWu3btYteuXVWHIUmSpJroaAQ5IvYDnwMC2A/8XmZui4hTgQ/SSsCPAd6bme/vNNgjcdlllwFt3gdZkiRJo1anI8j7MrMnM38eWATcWCz/JjAtM3uAXwTeHhEv6vBYR92UKVMYM2YMU6ZMYc2aNVWHI0mSpKOgmzXIJwJPAGTmf5WWH0dNSzne+973Mn36dLZu3cq8efMA6O3trTgqSZIkDadOE9exEdEXEQ8BfwEsObAiIiZExGeBXcC7MvMbHR7rqJs5cybHHHMMM2fOZNWqVSxdurTqkCRJkjTMulViMQk4H7gtIgIgM3dl5quBlwOXR8TP9N85IhZExL0Rce/jjz/eYSjDa/r06ezYsaPqMCRJkjTMulZikZnbI2IcMB74dmn5NyLiQeAs4M5++6wAVgBMnTo1uxVL2Vvf2p2bGm/dupXJkyd3pS1JkiSNXF2rDY6IScAYYE9EnBIRY4vlLwSmAzu7dax2zJ49m9mzZx/Rvps3b+bpp59m8+bNzJs3j8WLF3c5OkmSJI00nY4gj42IvuJ5AJdn5v6ImAzcHBFZLL8pMz/X4bGOyM6drbz8jDPOaHvfa665hh07djB58mSWLl3qBD1JkqRRoKMEOTPHDLL8Y8CrO2m7W6688krgyO6D/OCDD3Y5GkmSJI10tbz9miRJkjRcTJD7yZXDMldQkiRJNWGCLEmSJJWYIEuSJEkl3fyq6RHp2muvrToESZIk1UjjE+RZs2ZVHYIkSZJqpPEJcl9fHwA9PT1D32mSE/UkSZJGq8YnyAsXLgSO7D7IkiRJGn2cpCdJkiSVmCBLkiRJJSbIkiRJUokJsiRJklTS+El6N9xwQ9UhSJIkqUYanyCfeeaZVYcgSZKkGml8icW2bdvYtm1b1WFIkiSpJho/gvyOd7wD8D7IkiRJGprGjyBLkiRJ7TBBliRJkkpMkCVJkqQSE2RJkiSppPGT9JYtW1Z1CJIkSaqRxifIPT09VYcgSZKkGml8icXGjRvZuHFj1WFIkiSpJho/gnz99dcDMGvWrIojkSRJUh00fgRZkiRJaocJsiRJklRiggzwULQekiRJGvVMkCVJkqSSxk/Su/XWW6sOQZIkSTXS+AT5jDPOqDoESZIk1UjjSyzWr1/P+vXrqw5DkiRJNdH4EeSbb74ZgNmzZ1cciSRJkuqg8SPIhxPzY8DnkiRJGp1GfYIsSZIklZkgS5IkSSUdJcgRsT8i+iLigYi4PyLOLK3704j4fETsiIj3RMSIq19Ys2YN3FVa8GhloUiSJGmE6HSS3r7M7AGIiPOAG4Gzi0T5l4BXF9ttBc4GtnR4vLbdfvvtAy5fs2YNixcvhmmlhfe2lvf29h6d4CRJkjTidLPE4kTgieJ5AscDxwLHAccA3+risYZswoQJTJgw4VnLly5dyqpVq+BFpYVntZZLkiRp9Op0BHlsRPTRSoZPBs4ByMztEbEZ+CYQwPsyc0f/nSNiAbAAYOLEiR2GMrC1a9cCMGfOnIOW79ixg+nTp8MHSgt/FnZ8+FlhSpIkaRTpdAR5X2b2ZOYk4Hzgtmh5OTAZOAV4MXBORJzVf+fMXJGZUzNz6vjx4zsMZWC33HILt9xyy7OWT548ma1btx688N9byyVJkjR6da3EIjO3A+OA8cCvA5/OzKcy8yngHg6u9q3c4sWLmTdvHnyjtPCTreWSJEkavbqWIEfEJGAMsAf4Gq3Jes+NiGNoTdAbUbULvb29rXrj7aWFU3GCniRJ0ijXaYI8trjNWx+wFrg8M/cDd9K6adrngAeABzJzfYfH6rre3l64uLTgZZWFIkmSpBGio0l6mTlmkOX7gSs7aVuSJEmqQqd3sRjx7rzzzqpDkCRJUo00PkEeN27cIdfnyoSH4sfPJUmSNKp184tCRqTVq1ezevXqqsOQJElSTZggS5IkSSWNT5AlSZKkdpggS5IkSSWNn6Q3JJOcnCdJkqQWR5AlSZKkksaPIN99991VhyBJkqQaaXyCfMIJJ1QdgiRJkmqk8SUWy5cvZ/ny5VWHIUmSpJpofIK8bt061q1bV3UYkiRJqonGJ8iSJElSO0yQJUmSpBITZEmSJKnEBFmSJEkqicyR8S1yEfE48NVhan4csHuY2h5N7MfusB+7w37sDvuxO+zH7rAfu8N+HLpTM3N8/4UjJkEeThFxb2ZOrTqOurMfu8N+7A77sTvsx+6wH7vDfuwO+7FzllhIkiRJJSbIkiRJUsloSZBXVB1AQ9iP3WE/dof92B32Y3fYj91hP3aH/dihUVGDLEmSJA3VaBlBliRJkobEBFmSJEkqqWWCHBHnR8TOiHgkIt4+wPrjImJtsf5fIuK00rpFxfKdEXHeUNtsoiPtx4j4lYi4LyI+V/x7TmmfLUWbfcXjp4/iKVWig348LSL2lfrq/aV9/lvRv49ExHsiIo7iKVWig358c6kP+yLihxHRU6zzenz2+l+OiPsj4pmIuKTfussj4ovF4/LS8lF1PR5pH0ZET0Rsj4jPR8RnI2JOad3qiPhy6VrsOUqnU5kOr8X9pb76UGn5S4r3/yPF58GxR+NcqtTB9Tiz32fj9yPijcW6UXc9ti0za/UAxgCPAi8FjgUeAF7Zb5urgfcXz98ErC2ev7LY/jjgJUU7Y4bSZtMeHfbja4AXFc+nAF8v7bMFmFr1+dWkH08DHhyk3X8FXg8EcA9wQdXnOlL7sd82rwIeLb32enx2P54GvBq4DbiktPyngC8V/76weP7CYt2ouR477MPTgVcUz18EfBN4QfF6dXnbpj866cdi3VODtLsOeFPx/P3AVVWf60jux9I2PwV8BziheD2qrscjedRxBPl1wCOZ+aXM/C/gb4E39NvmDcBfF8/vBM4tRjzeAPxtZv4gM78MPFK0N5Q2m+aI+zEzP5OZ3yiWfx4YGxHHHZWoR55OrscBRcTJwImZ+elsfZLdBryx65GPLN3qx95i39HqsP2YmV/JzM8CP+y373nAxzLzO5n5BPAx4PxReD0ecR9m5sOZ+cXi+TeAbwPP+oauUaKTa3FAxfv9HFrvf2h9HryxaxGPTN3qx0uAezJz7/CF2ix1TJBfDOwqvX6sWDbgNpn5DPAfwEmH2HcobTZNJ/1YdjFwf2b+oLTsr4o/2VzX9D/F0nk/viQiPhMRH4+Is0rbP3aYNpumW9fjHGBNv2Vej53tO9qux678PIiI19Ea8Xu0tHhpUXrxf0bBoEKn/Xh8RNwbEZ8+UBZA6/3+ZPH+P5I266hb+cmbePZn42i6HttWxwRZI0RE/BzwLuDK0uI3Z+argLOKx2VVxFYT3wQmZuZrgD8APhARJ1YcU21FxC8CezPzwdJir0cddcWo++3Ab2fmgVG9RcAk4LW0/tz9vyoKry5OzdZXJf8msCwiXlZ1QHVVXI+vAj5SWuz1eBh1TJC/DkwovT6lWDbgNhHxXOAngT2H2HcobTZNJ/1IRJwCfBD4rcz80QhJZn69+Pd7wAdo/XmoyY64H4tSnz0AmXkfrZGm04vtTzlMm03T0fVYeNYIiddjW9fOoT4fR9P12NHPg+KX3H8CFmfmpw8sz8xvZssPgL/Ca/GQSu/dL9GaS/AaWu/3FxTv/7bbrKlu5CeXAh/MzKcPLBiF12Pb6pgg/xvwimIm67G0fih+qN82HwIOzMC+BPjnonbuQ8CbojUb/iXAK2hNPhlKm01zxP0YES+g9QPg7Zn5qQMbR8RzI2Jc8fwY4CLgQZqtk34cHxFjACLipbSuxy9l5jeB70bE64uSgN8C/vFonEyFOnlfExHPofVD4Ef1x16PbX+WfQT41Yh4YUS8EPhV4COj8Ho84j4stv8gcFtm3tlv3cnFv0GrbtZrcRDFNXhc8Xwc8EvAF4r3+2Za739ofR40+VqE7uQnvfQbPBiF12P7qp4leCQP4ELgYVojbouLZe8E/p/i+fHA39GahPevwEtL+y4u9ttJaSb2QG02/XGk/QhcC/wn0Fd6/DTwE8B9wGdpTd77c2BM1ec5gvvx4qKf+oD7gdmlNqfS+sB6FHgfxbdeNvnR4ft6BvDpfu15PQ7cj6+lVcf4n7RG5D5f2vd3iv59hFZ5wKi8Ho+0D4G5wNP9Pht7inX/DHyu6Mc7gOdVfZ4juB/PLPrqgeLfeaU2X1q8/x8pPg+Oq/o8R2o/FutOozXi/Jx+bY6667Hdh181LUmSJJXUscRCkiRJGjYmyJIkSVKJCbIkSZJUYoIsSZIklZggS5IkSSUmyJIkSVKJCbIkSZJU8n8ByD97yw5mtLAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming clf is your trained RandomForestClassifier model\n",
    "# and X_test, y_test are your test datasets\n",
    "\n",
    "result = permutation_importance(clf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Sorting features by importance\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "bp = ax.boxplot(result.importances[sorted_idx].T, vert=False, labels=X_test.columns[sorted_idx],\n",
    "                patch_artist=True,  # To fill with color\n",
    "                )\n",
    "\n",
    "# Customizing the boxplot color to dark green\n",
    "for box in bp['boxes']:\n",
    "    # Change box color\n",
    "    box.set(color='darkgreen', linewidth=2)  # Box edge color\n",
    "    box.set(facecolor='darkgreen')  # Box fill color\n",
    "\n",
    "# Optionally, customize whiskers, fliers, caps, and medians if needed\n",
    "for whisker in bp['whiskers']:\n",
    "    whisker.set(color='darkgreen', linewidth=2)\n",
    "for cap in bp['caps']:\n",
    "    cap.set(color='darkgreen', linewidth=2)\n",
    "for median in bp['medians']:\n",
    "    median.set(color='gold', linewidth=2)  # Making the median stand out\n",
    "\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_title(\"Permutation Importances Round 5 No. 9 (test set)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('r5_n9_features.png', bbox_inches='tight', pad_inches=0, facecolor='white')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
